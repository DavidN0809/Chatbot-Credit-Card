{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4e95d4-31a1-4aae-9b17-0accf2c76a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae67b3f7-d781-4d5c-a92c-dbf4bbdf463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login --token key   \n",
    "# wandb login --relogin key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22140ac5-0ef7-42df-9eb0-d1d5f8def36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdnicho26\u001b[0m (\u001b[33mdnicho26-university-of-north-carolina-at-charlotte\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6ee03af58b480ea76f028722aee9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111429471089246, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/notebooks/Chatbot-Credit-Card/wandb/run-20241023_220653-dsrw3c4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/dsrw3c4y' target=\"_blank\">curious-yogurt-21</a></strong> to <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/dsrw3c4y' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/dsrw3c4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3 on CC Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a97b2a-5ea0-4c90-b4ba-0c05e83f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "new_model = \"/opt/notebooks/Chatbot-Credit-Card/models/llama-3.2-3b-CC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765187fa-57b1-4600-90ae-78bb4a442e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfaa4237-421d-4b1b-8322-2d6728f97d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a0cf5dc2e344e1a14bc078a27a1ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59d5ea6e166425c873d99f70b289902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204270da79e4452a901a2c7f1aa20d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1506126d4cb842bea7bb6cf465928a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b46496de3b492a99a06afa1b5ea658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee93cb3dbc0c423abce49b186f9783b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e1fe18ba4f43e8bb48e3a513e7c3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5a2b95d301433f99174a9bd0033f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd36b5176524c7cb43422723619040a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b0cf66a16a49a1953c4a799332d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c9fc4d-7637-4dc9-b335-5733a304c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Income, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Black</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Income, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Income, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to YearsEmpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByOtherMeans</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Income, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This application was denied due to Employed, Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Energy</td>\n",
       "      <td>White</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>200</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>This application was denied due to Income, Zip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Latino</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This application was denied due to Income, Zip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ConsumerStaples</td>\n",
       "      <td>White</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>280</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>This application was denied due to YearsEmploy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Black</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This application was denied due to Employed, C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender    Age    Debt  Married  BankCustomer         Industry Ethnicity  \\\n",
       "0         1  30.83   0.000        1             1      Industrials     White   \n",
       "1         0  58.67   4.460        1             1        Materials     Black   \n",
       "2         0  24.50   0.500        1             1        Materials     Black   \n",
       "3         1  27.83   1.540        1             1      Industrials     White   \n",
       "4         1  20.17   5.625        1             1      Industrials     White   \n",
       "..      ...    ...     ...      ...           ...              ...       ...   \n",
       "685       1  21.08  10.085        0             0        Education     Black   \n",
       "686       0  22.67   0.750        1             1           Energy     White   \n",
       "687       0  25.25  13.500        0             0       Healthcare    Latino   \n",
       "688       1  17.92   0.205        1             1  ConsumerStaples     White   \n",
       "689       1  35.00   3.375        1             1           Energy     Black   \n",
       "\n",
       "     YearsEmployed  PriorDefault  Employed  CreditScore  DriversLicense  \\\n",
       "0             1.25             1         1            1               0   \n",
       "1             3.04             1         1            6               0   \n",
       "2             1.50             1         0            0               0   \n",
       "3             3.75             1         1            5               1   \n",
       "4             1.71             1         0            0               0   \n",
       "..             ...           ...       ...          ...             ...   \n",
       "685           1.25             0         0            0               0   \n",
       "686           2.00             0         1            2               1   \n",
       "687           2.00             0         1            1               1   \n",
       "688           0.04             0         0            0               0   \n",
       "689           8.29             0         0            0               1   \n",
       "\n",
       "          Citizen  ZipCode  Income  Approved  \\\n",
       "0         ByBirth      202       0         1   \n",
       "1         ByBirth       43     560         1   \n",
       "2         ByBirth      280     824         1   \n",
       "3         ByBirth      100       3         1   \n",
       "4    ByOtherMeans      120       0         1   \n",
       "..            ...      ...     ...       ...   \n",
       "685       ByBirth      260       0         0   \n",
       "686       ByBirth      200     394         0   \n",
       "687       ByBirth      200       1         0   \n",
       "688       ByBirth      280     750         0   \n",
       "689       ByBirth        0       0         0   \n",
       "\n",
       "                                                Reason  \n",
       "0    This application was approved due to Income, Y...  \n",
       "1    This application was approved due to Income, Y...  \n",
       "2    This application was approved due to Income, Y...  \n",
       "3    This application was approved due to YearsEmpl...  \n",
       "4    This application was approved due to Income, Y...  \n",
       "..                                                 ...  \n",
       "685  This application was denied due to Employed, Z...  \n",
       "686  This application was denied due to Income, Zip...  \n",
       "687  This application was denied due to Income, Zip...  \n",
       "688  This application was denied due to YearsEmploy...  \n",
       "689  This application was denied due to Employed, C...  \n",
       "\n",
       "[690 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/opt/notebooks/Chatbot-Credit-Card/dataset/cleaned-augmented.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdf9bec-3a1a-44d7-a003-001201de0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  <gender> Male </gender> <age> 30.83 </age> <de...   \n",
      "1  <gender> Female </gender> <age> 58.67 </age> <...   \n",
      "2  <gender> Female </gender> <age> 24.5 </age> <d...   \n",
      "3  <gender> Male </gender> <age> 27.83 </age> <de...   \n",
      "4  <gender> Male </gender> <age> 20.17 </age> <de...   \n",
      "\n",
      "                                               label  \n",
      "0  <approved> Yes </approved> <reason> This appli...  \n",
      "1  <approved> Yes </approved> <reason> This appli...  \n",
      "2  <approved> Yes </approved> <reason> This appli...  \n",
      "3  <approved> Yes </approved> <reason> This appli...  \n",
      "4  <approved> Yes </approved> <reason> This appli...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to preprocess the data with special tokens for fine-tuning LLaMA3\n",
    "def preprocess_data_generalized(row):\n",
    "    # Generate text for each input feature with special tokens\n",
    "    gender_text = f\"<gender> {'Male' if row['Gender'] == 1 else 'Female'} </gender>\"\n",
    "    age_text = f\"<age> {row['Age']} </age>\"\n",
    "    debt_text = f\"<debt> {row['Debt']} </debt>\"\n",
    "    married_text = f\"<married> {'Yes' if row['Married'] == 1 else 'No'} </married>\"\n",
    "    bank_customer_text = f\"<bank_customer> {'Yes' if row['BankCustomer'] == 1 else 'No'} </bank_customer>\"\n",
    "    industry_text = f\"<industry> {row['Industry']} </industry>\"\n",
    "    ethnicity_text = f\"<ethnicity> {row['Ethnicity']} </ethnicity>\"\n",
    "    years_employed_text = f\"<years_employed> {row['YearsEmployed']} </years_employed>\"\n",
    "    prior_default_text = f\"<prior_default> {'Yes' if row['PriorDefault'] == 1 else 'No'} </prior_default>\"\n",
    "    employed_text = f\"<employed> {'Yes' if row['Employed'] == 1 else 'No'} </employed>\"\n",
    "    credit_score_text = f\"<credit_score> {row['CreditScore']} </credit_score>\"\n",
    "    drivers_license_text = f\"<drivers_license> {'Yes' if row['DriversLicense'] == 1 else 'No'} </drivers_license>\"\n",
    "    citizen_text = f\"<citizen> {row['Citizen']} </citizen>\"\n",
    "    zip_code_text = f\"<zip_code> {row['ZipCode']} </zip_code>\"\n",
    "    income_text = f\"<income> {row['Income']} </income>\"\n",
    "\n",
    "    # Combine all input text with special tokens\n",
    "    input_text = \" \".join([\n",
    "        gender_text, age_text, debt_text, married_text, bank_customer_text, \n",
    "        industry_text, ethnicity_text, years_employed_text, prior_default_text, \n",
    "        employed_text, credit_score_text, drivers_license_text, citizen_text, \n",
    "        zip_code_text, income_text\n",
    "    ])\n",
    "    \n",
    "    # Output format for LLaMA fine-tuning (using special tokens for labels)\n",
    "    output_text = f\"<approved> {'Yes' if row['Approved'] == 1 else 'No'} </approved> <reason> {row['Reason']} </reason>\"\n",
    "    \n",
    "    return {\"text\": input_text, \"label\": output_text}\n",
    "\n",
    "# Apply the generalized preprocessing to the dataframe\n",
    "df_processed = df.apply(preprocess_data_generalized, axis=1)\n",
    "df_final = pd.DataFrame(df_processed.tolist())\n",
    "\n",
    "# Display the first few rows of the processed data\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a905ad7-0c94-474c-8bf0-fd0ce3947412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<gender> Male </gender> <age> 27.83 </age> <debt> 1.54 </debt> <married> Yes </married> <bank_customer> Yes </bank_customer> <industry> Industrials </industry> <ethnicity> White </ethnicity> <years_employed> 3.75 </years_employed> <prior_default> Yes </prior_default> <employed> Yes </employed> <credit_score> 5 </credit_score> <drivers_license> Yes </drivers_license> <citizen> ByBirth </citizen> <zip_code> 100 </zip_code> <income> 3 </income>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df_final)\n",
    "dataset['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628662d7-9884-4cd1-91a6-b98ee2ed8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base_layer']\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "646c87a7-42d3-4f1e-8398-33966ca2ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c81be27d-7296-4c4c-9dbc-f3831088680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07efe722-52f0-48e6-b245-45d1f5e99dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c104961c955d4327a3e3fa3eff87c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/552 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee92643323a44cdfa89c680f299856c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Assuming dataset is a Dataset object with columns 'text' and 'label'\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)  # Split into 80% train, 20% test\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=512,\n",
    "    dataset_text_field=\"text\",  # The column containing the input text\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110c3802-f9a9-4b41-a0b8-30752f92edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/2760 00:05 < 1:59:10, 0.39 it/s, Epoch 0.01/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447dfccc-9e52-4618-8e4e-a40d81c22e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37b01f-073b-4f33-8f5c-e7a4b921a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction tailored to credit card approval context\n",
    "instruction = \"\"\"You are a highly knowledgeable financial advisor specializing in credit card approvals. \n",
    "    Be informative, polite, and provide clear responses to any queries regarding credit approval decisions.\n",
    "    \"\"\"\n",
    "\n",
    "# Example message (user asking about credit card approval)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": \"Can I know why my credit card application was rejected? My age is 30, income is $40,000, and credit score is 580.\"}\n",
    "]\n",
    "\n",
    "# Generate the prompt using the chat template (assuming tokenizer.apply_chat_template is a custom method for your setup)\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Tokenize the prompt\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "# Generate model outputs (adjusting parameters if necessary)\n",
    "outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Decode the model's response\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the assistant's response (assuming the response begins after the 'assistant' token)\n",
    "print(text.split(\"assistant\")[1])\n",
    "\n",
    "# Save the fine-tuned model and tokenizer for future use\n",
    "model.save_pretrained(new_model)\n",
    "tokenizer.save_pretrained(new_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6943f-4fdb-4704-9ada-897a202c9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example custom prompt provided by the user\n",
    "custom_prompt = \"Age: 27.83, CreditScore: 5, Income: 3, YearsEmployed: 3.75, Gender: Male, Married: Yes, Industry: Industrials, Ethnicity: White, PriorDefault: Yes, Employed: Yes\"\n",
    "\n",
    "# You don't need a system message if you are simply testing this input directly\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": instruction},\n",
    "    {\"role\": \"user\", \"content\": custom_prompt}\n",
    "]\n",
    "\n",
    "# Generate the prompt using the chat template (if using custom chat template generation)\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Tokenize the custom prompt\n",
    "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
    "\n",
    "# Generate output from the model\n",
    "outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n",
    "\n",
    "# Decode the model's response\n",
    "response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the assistant's response\n",
    "print(response_text.split(\"assistant\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece5479-43bc-4ff3-a1e5-fd92861b720a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
