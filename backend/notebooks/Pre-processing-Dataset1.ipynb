{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0bcfb3",
   "metadata": {
    "papermill": {
     "duration": 2.228587,
     "end_time": "2024-11-04T15:49:19.212643",
     "exception": false,
     "start_time": "2024-11-04T15:49:16.984056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\n",
    "# Load the application_record dataset\n",
    "data = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/application_record.csv\")\n",
    "\n",
    "# Load the credit_record dataset\n",
    "record = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/credit_record.csv\")\n",
    "\n",
    "# Flag to skip training and load the saved model\n",
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1cfd6-fe59-4de9-bbf1-94fb039b5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first account open month for each user\n",
    "begin_month = record.loc[record.groupby(\"ID\")[\"MONTHS_BALANCE\"].idxmin()]\n",
    "begin_month = begin_month.rename(columns={\"MONTHS_BALANCE\": \"begin_month\"})\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(data, begin_month, how=\"left\", on=\"ID\")\n",
    "print(\"Datasets loaded and merged successfully.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99509a2-841e-48dd-8805-a677c438c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define approval logic based on multiple criteria\n",
    "def determine_approval(row):\n",
    "    # Define custom approval logic\n",
    "    if row[\"STATUS\"] in [\"0\", \"1\", \"C\", \"X\"]:  # Good credit status\n",
    "            return 1  # Approved\n",
    "    return 0  # Default to denial if STATUS is bad or missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1824bbb-2201-4ee2-9516-513ac49f95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logic to determine approval (filling missing STATUS values first)\n",
    "record[\"STATUS\"] = record[\"STATUS\"].fillna(\"X\")  # Handle missing values\n",
    "record[\"Approved\"] = record.apply(determine_approval, axis=1)\n",
    "\n",
    "# Aggregate approval status for each ID (disapproval if any ID has disqualifying criteria)\n",
    "approval_status = record.groupby(\"ID\")[\"Approved\"].min().reset_index()\n",
    "\n",
    "# Merge approval status back into the main dataset, avoiding \"_x\" and \"_y\" columns\n",
    "df = pd.merge(data, approval_status, how=\"left\", on=\"ID\")\n",
    "df[\"Approved\"] = df[\"Approved\"].fillna(0).astype(int)  # Fill missing approvals as denial\n",
    "print(\"Approval status merged successfully.\")\n",
    "\n",
    "# Display the head of the resulting DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fb522-35a1-4588-bc31-23f10c20e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the 'DAYS_BIRTH' column to convert days to years\n",
    "df['DAYS_BIRTH'] = (-df['DAYS_BIRTH'] // 365).fillna(0).astype(int)\n",
    "\n",
    "# Preprocess the 'DAYS_EMPLOYED' column to get absolute values and handle unemployment\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "\n",
    "# # Convert 'begin_month' to positive months if it exists, indicating the number of months ago\n",
    "# if 'begin_month' in df.columns:\n",
    "#     df['begin_month'] = df['begin_month'].abs()\n",
    "\n",
    "# Handle missing or infinite values in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())  # Fill NaN with median values\n",
    "\n",
    "# Display a sample of the processed dataset\n",
    "print(\"Preprocessing completed successfully.\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af597de2-459d-4542-ad61-202df2c94a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature mapping dictionary\n",
    "feature_mapping = {\n",
    "    'CODE_GENDER': 'Gender',\n",
    "    'FLAG_OWN_CAR': 'Car Ownership',\n",
    "    'FLAG_OWN_REALTY': 'Property Ownership',\n",
    "    'CNT_CHILDREN': 'Number of Children',\n",
    "    'AMT_INCOME_TOTAL': 'Annual Income',\n",
    "    'NAME_INCOME_TYPE': 'Income Category',\n",
    "    'NAME_EDUCATION_TYPE': 'Education Level',\n",
    "    'NAME_FAMILY_STATUS': 'Marital Status',\n",
    "    'NAME_HOUSING_TYPE': 'Housing Type',\n",
    "    'DAYS_BIRTH': 'Age (Days)',\n",
    "    'DAYS_EMPLOYED': 'Employment Duration (Days)',\n",
    "    'FLAG_MOBIL': 'Mobile Phone',\n",
    "    'FLAG_WORK_PHONE': 'Work Phone',\n",
    "    'FLAG_PHONE': 'Phone',\n",
    "    'FLAG_EMAIL': 'Email',\n",
    "    'OCCUPATION_TYPE': 'Occupation',\n",
    "    'CNT_FAM_MEMBERS': 'Family Size',\n",
    "    'ID': 'Client Number',\n",
    "    'STATUS': 'Credit Status'\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame using the mapping\n",
    "df.rename(columns=feature_mapping, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721a4cf",
   "metadata": {
    "papermill": {
     "duration": 0.029387,
     "end_time": "2024-11-04T15:49:19.247256",
     "exception": false,
     "start_time": "2024-11-04T15:49:19.217869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'TARGET': 'Approved'}, inplace=True)\n",
    "# Display the first few rows to confirm the change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ced58-95b1-4ca3-8564-4b271549ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-Training Preprocessing (for model training)\n",
    "# # Convert Age (Days) to Age (Years) as a numerical feature\n",
    "# df['Age (Days)'] = (-df['Age (Days)'] // 365).astype(int)\n",
    "\n",
    "# # Convert Employment Duration to numerical days or binary status\n",
    "# df['Employment Duration (Days)'] = df['Employment Duration (Days)'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "\n",
    "# # Keep Months Balance as numerical data for training\n",
    "# df['Months Balance'] = df['Months Balance'].abs()\n",
    "\n",
    "# # Display preprocessed data for training\n",
    "# print(\"Preprocessed Data for Training:\")\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f38328",
   "metadata": {
    "papermill": {
     "duration": 0.866269,
     "end_time": "2024-11-04T15:49:20.118453",
     "exception": false,
     "start_time": "2024-11-04T15:49:19.252184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "# Automatically identify categorical columns from the dataframe based on data types\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Identify potential categorical columns stored as numbers by checking unique values\n",
    "for col in df.columns:\n",
    "    if col != 'Approved':  # Skip 'Approved' column\n",
    "        if df[col].nunique() < 10 and col not in categorical_cols:  # Arbitrary threshold of < 10 unique values\n",
    "            categorical_cols.append(col)\n",
    "\n",
    "# Display identified categorical columns\n",
    "print(f\"Identified Categorical Columns (excluding 'Approved'): {categorical_cols}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7864f",
   "metadata": {
    "papermill": {
     "duration": 0.893371,
     "end_time": "2024-11-04T15:49:21.017061",
     "exception": false,
     "start_time": "2024-11-04T15:49:20.123690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store bad predictors\n",
    "bad_predictors = []\n",
    "\n",
    "# You can change the threshold for what is considered a \"bad predictor\"\n",
    "p_value_threshold = 0.05  # Adjust this if needed\n",
    "\n",
    "# Evaluate each categorical column using chi-squared test\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}:\")\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    a = np.array(pd.crosstab(df['Approved'], df[col]))\n",
    "    stats, p, dof, _ = chi2_contingency(a, correction=False)\n",
    "    \n",
    "    if p > p_value_threshold:\n",
    "        print(Fore.RED + f\"'{col}' is a 'bad Predictor'\")\n",
    "        print(f\"p_val = {p}\\n\")\n",
    "        bad_predictors.append(col)  # Append the bad predictor to the list\n",
    "    else:\n",
    "        print(Fore.GREEN + f\"'{col}' is a 'Good Predictor'\")\n",
    "        print(f\"p_val = {p}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbfa9b",
   "metadata": {
    "papermill": {
     "duration": 0.100989,
     "end_time": "2024-11-04T15:49:21.123552",
     "exception": false,
     "start_time": "2024-11-04T15:49:21.022563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically drop bad predictors\n",
    "df.drop(bad_predictors, axis=1, inplace=True)\n",
    "\n",
    "# Print the final dataframe structure after dropping\n",
    "print(f\"Dropped bad predictors: {bad_predictors}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be55e2",
   "metadata": {
    "papermill": {
     "duration": 0.101643,
     "end_time": "2024-11-04T15:49:21.232687",
     "exception": false,
     "start_time": "2024-11-04T15:49:21.131044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()  # Removes leading and trailing spaces from all column names\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Print columns to verify correctness\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)\n",
    "\n",
    "# Remove 'Approved' if it's in either list\n",
    "if 'Approved' in categorical_cols:\n",
    "    categorical_cols.remove('Approved')\n",
    "if 'Approved' in numerical_cols:\n",
    "    numerical_cols.remove('Approved')\n",
    "\n",
    "# Check the results\n",
    "print(\"Categorical columns after removal:\", categorical_cols)\n",
    "print(\"Numerical columns after removal:\", numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192a365",
   "metadata": {
    "papermill": {
     "duration": 0.018793,
     "end_time": "2024-11-04T15:49:21.257785",
     "exception": false,
     "start_time": "2024-11-04T15:49:21.238992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Data types of the columns:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nCategorical columns identified:\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e119b2",
   "metadata": {
    "papermill": {
     "duration": 1.089242,
     "end_time": "2024-11-04T15:49:22.354366",
     "exception": false,
     "start_time": "2024-11-04T15:49:21.265124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Initialize LabelEncoders for categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col != 'Approved':  # Exclude the target column from encoding\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le  # Store the encoder for future use (e.g., inverse_transform)\n",
    "\n",
    "print(\"Unique values in categorical columns after encoding:\")\n",
    "for col in categorical_cols:\n",
    "    if col != 'Approved':  # Ensure target is not being encoded\n",
    "        print(f\"{col}: {df[col].unique()}\")\n",
    "print(\"\\nData types of the columns after encoding:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b620ef0",
   "metadata": {
    "papermill": {
     "duration": 0.027339,
     "end_time": "2024-11-04T15:49:22.388304",
     "exception": false,
     "start_time": "2024-11-04T15:49:22.360965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cf5c5",
   "metadata": {
    "papermill": {
     "duration": 0.923742,
     "end_time": "2024-11-04T15:49:23.318362",
     "exception": false,
     "start_time": "2024-11-04T15:49:22.394620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select numerical features (excluding 'Approved')\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Remove 'Approved' from the list of columns to scale\n",
    "if 'Approved' in numerical_cols:\n",
    "    numerical_cols.remove('Approved')\n",
    "train_df = df.copy()\n",
    "\n",
    "# Scale only the numerical feature columns\n",
    "scaler = StandardScaler()\n",
    "train_df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = train_df.drop('Approved', axis=1)  # Drop 'Approved' from features\n",
    "y = train_df['Approved']  # Target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting splits\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954f505",
   "metadata": {
    "papermill": {
     "duration": 0.042536,
     "end_time": "2024-11-04T15:49:23.367614",
     "exception": false,
     "start_time": "2024-11-04T15:49:23.325078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_df['Approved'].value_counts())  # Ensure the target has values like 0/1 or yes/no\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bae6a9",
   "metadata": {
    "papermill": {
     "duration": 0.037465,
     "end_time": "2024-11-04T15:49:23.412466",
     "exception": false,
     "start_time": "2024-11-04T15:49:23.375001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e5688a",
   "metadata": {
    "papermill": {
     "duration": 0.052994,
     "end_time": "2024-11-04T15:49:23.472774",
     "exception": false,
     "start_time": "2024-11-04T15:49:23.419780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reduce dataset size using stratified sampling (optional)\n",
    "# X_sample, _, y_sample, _ = train_test_split(X, y, train_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef475ac",
   "metadata": {
    "papermill": {
     "duration": 95.153152,
     "end_time": "2024-11-04T15:50:58.634180",
     "exception": false,
     "start_time": "2024-11-04T15:49:23.481028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Set up K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Directory to save the best model\n",
    "model_save_dir = \"/opt/notebooks/Chatbot-Credit-Card/backend/models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# List of models to evaluate with optimizations\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, ccp_alpha=0.01, max_depth=6, min_samples_split=20),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=50, max_depth=6, n_jobs=-1, min_samples_split=10, max_features='sqrt'),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, C=0.5, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss', tree_method='gpu_hist', n_estimators=50, max_depth=6, subsample=0.8, colsample_bytree=0.8, reg_lambda=10)\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results and trained models\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "# Iterate over each model with cross-validation\n",
    "for model_name, model in models.items():\n",
    "    if skip_training:\n",
    "        model_files = [f for f in os.listdir(model_save_dir) if f.endswith(\".pkl\")]\n",
    "        if len(model_files) == 1:\n",
    "            model_path = os.path.join(model_save_dir, model_files[0])\n",
    "            print(f\"Loading the only available model: {model_files[0]}\")\n",
    "            with open(model_path, \"rb\") as f:\n",
    "                best_model = pickle.load(f)\n",
    "            print(f\"Loaded model: {model_files[0]}\")\n",
    "            # You might want to load additional metadata here if needed.\n",
    "            exit(0)  # Exit as training is skipped\n",
    "        elif len(model_files) == 0:\n",
    "            print(\"No saved models found. Cannot skip training.\")\n",
    "            skip_training = False\n",
    "        else:\n",
    "            print(\"Multiple models found. Training will proceed to select the best one.\")\n",
    "            skip_training = False\n",
    "    if not skip_training or not os.path.exists(model_path):\n",
    "        # Cross-validate the model\n",
    "        cv_accuracy = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy').mean()\n",
    "        cv_f1 = cross_val_score(model, X_train, y_train, cv=kf, scoring='f1').mean()\n",
    "        cv_auc = cross_val_score(model, X_train, y_train, cv=kf, scoring='roc_auc').mean()\n",
    "        cv_mae = -cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error').mean()\n",
    "        \n",
    "        # Train the model on the full training data\n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[model_name] = model  # Store the trained model\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # For AUC-ROC, we need the probability scores for the positive class\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        test_auc = roc_auc_score(y_test, y_test_prob) if y_test_prob is not None else None\n",
    "        \n",
    "        # Check if any metric is 1.0, and skip such models\n",
    "        if test_accuracy == 1.0 or test_auc == 1.0 or test_f1 == 1.0 or test_mae == 0.0:\n",
    "            print(f\"{model_name} is overfitting with a metric of 1.0, skipping this model.\")\n",
    "            continue\n",
    "        \n",
    "        # Store the evaluation results\n",
    "        results[model_name] = {\n",
    "            \"CV Accuracy\": cv_accuracy,\n",
    "            \"CV AUC\": cv_auc,\n",
    "            \"CV MAE\": cv_mae,\n",
    "            \"CV F1\": cv_f1,\n",
    "            \"Test Accuracy\": test_accuracy,\n",
    "            \"Test AUC\": test_auc,\n",
    "            \"Test MAE\": test_mae,\n",
    "            \"Test F1\": test_f1\n",
    "        }\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Filter out models with any 1.0 metric, if any are left\n",
    "filtered_results = {model: metrics for model, metrics in results.items()\n",
    "                    if all(metric != 1.0 for metric in metrics.values())}\n",
    "\n",
    "# If no models remain after filtering, display a message\n",
    "if not filtered_results:\n",
    "    print(\"\\nNo models remain after filtering out overfitting models with metrics of 1.0.\")\n",
    "else:\n",
    "    best_model_name = max(filtered_results, key=lambda x: (\n",
    "        filtered_results[x][\"Test Accuracy\"] / 1.0 +  # Normalize to [0,1]\n",
    "        filtered_results[x][\"Test AUC\"] / 1.0 +\n",
    "        filtered_results[x][\"Test F1\"] / 1.0 -\n",
    "        filtered_results[x][\"Test MAE\"] / 100.0      # Scale appropriately\n",
    "    ))\n",
    "\n",
    "    best_model = trained_models[best_model_name]  # Retrieve the trained best model\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"Best Model Metrics: {filtered_results[best_model_name]}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    model_path = os.path.join(model_save_dir, f\"{best_model_name.replace(' ', '_')}.pkl\")\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model saved: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c053ddb-3193-4643-9f8f-9481f7da0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a211355",
   "metadata": {
    "papermill": {
     "duration": 4.298478,
     "end_time": "2024-11-04T15:51:02.942970",
     "exception": false,
     "start_time": "2024-11-04T15:50:58.644492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings from LIME (optional)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialize the LimeTabularExplainer with training data\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=X_train.values,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    class_names=['Not Approved', 'Approved'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Define a prediction function for LIME\n",
    "def predict_fn(x):\n",
    "    return best_model.predict_proba(x)\n",
    "\n",
    "# Pick a single instance from the test set to explain\n",
    "i = 0  # Index of the instance to explain\n",
    "instance = X_test.iloc[i]\n",
    "# num_features = X_train.shape[1]  # Total number of features\n",
    "\n",
    "# Generate explanation for the instance\n",
    "exp = lime_explainer.explain_instance(\n",
    "    data_row=instance.values,\n",
    "    predict_fn=predict_fn,\n",
    "    # num_features=num_features\n",
    ")\n",
    "\n",
    "# Display the explanation for the instance\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f3f74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-11-04T15:51:02.994293",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Suppress specific warnings from LIME (optional)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Function to extract the feature name from the LIME explanation\n",
    "# Modify the function to include feature values in the explanation\n",
    "def extract_feature_value(feature_str, instance):\n",
    "    # Extract feature name\n",
    "    split_symbols = ['<=', '>=', '<', '>', '!=', '=']\n",
    "    for symbol in split_symbols:\n",
    "        if symbol in feature_str:\n",
    "            feature_name = feature_str.split(symbol)[0].strip()\n",
    "            break\n",
    "    else:\n",
    "        feature_name = feature_str.strip()\n",
    "\n",
    "    # Remove non-alphanumeric characters except spaces\n",
    "    cleaned_feature_name = re.sub(r'[^A-Za-z0-9 ]+', '', feature_name).strip()\n",
    "\n",
    "    # Map cleaned feature name back to the dataset's column names\n",
    "    actual_feature_name = next(\n",
    "        (col for col in instance.index if cleaned_feature_name.lower() in col.lower()), \n",
    "        None\n",
    "    )\n",
    "\n",
    "    if actual_feature_name is None:\n",
    "        raise KeyError(f\"Feature '{cleaned_feature_name}' not found in dataset columns.\")\n",
    "\n",
    "    # Retrieve the actual value of the feature\n",
    "    feature_value = instance[actual_feature_name]\n",
    "    return f\"{actual_feature_name} {feature_value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766fd1e-f8d3-41d7-97c4-47554de6e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Initialize the LimeTabularExplainer with the feature dataset (exclude 'Approved' column)\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=X.values,  # Use X instead of df\n",
    "    feature_names=X.columns.tolist(),\n",
    "    class_names=['Not Approved', 'Approved'],  # Adjust according to your dataset\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store explanations\n",
    "explanations = []\n",
    "\n",
    "# Define a prediction function compatible with LIME (outside the loop)\n",
    "def predict_fn(x):\n",
    "    return best_model.predict_proba(x)\n",
    "\n",
    "# Adjust the loop to include feature values in the explanation\n",
    "for idx, instance in tqdm(X.iterrows(), total=X.shape[0], desc=\"Generating Explanations\"):\n",
    "    # Ensure instance is in the correct format\n",
    "    instance_values = instance.values.reshape(1, -1)\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = best_model.predict(instance_values)[0]\n",
    "    actual_label = y.loc[idx]\n",
    "    \n",
    "    # Generate explanation for the instance\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        data_row=instance.values,\n",
    "        predict_fn=predict_fn,\n",
    "        num_features=len(X.columns)\n",
    "    )\n",
    "    \n",
    "    explanation_list = exp.as_list()\n",
    "    decision = 'Approved' if prediction == 1 else 'Denied'\n",
    "    \n",
    "    features_contributing = []\n",
    "    for feature, weight in explanation_list:\n",
    "        if (prediction == 1 and weight > 0) or (prediction == 0 and weight < 0):\n",
    "            try:\n",
    "                feature_with_value = extract_feature_value(feature, instance)\n",
    "                if feature_with_value and feature_with_value not in features_contributing:\n",
    "                    features_contributing.append(feature_with_value)\n",
    "            except KeyError:\n",
    "                # Handle the case where the feature is not found\n",
    "                continue\n",
    "    \n",
    "    if features_contributing:\n",
    "        explanation_text = f\"This application was {decision.lower()} due to \" + \", \".join(features_contributing) + \".\"\n",
    "    else:\n",
    "        explanation_text = f\"This application was {decision.lower()}.\"\n",
    "    \n",
    "    explanations.append({\n",
    "        'Index': idx,\n",
    "        'Prediction': decision,\n",
    "        'Actual': 'Approved' if actual_label == 1 else 'Denied',\n",
    "        'Explanation': explanation_text\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381db5e-9b05-4db9-b3d0-a4121a1478cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of explanations generated: {len(explanations)}\")\n",
    "print(f\"Total number of instances: {X.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73061c8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert explanations to DataFrame\n",
    "explanations_df = pd.DataFrame(explanations)\n",
    "\n",
    "# Set 'Index' as the DataFrame index to align with df\n",
    "explanations_df.set_index('Index', inplace=True)\n",
    "\n",
    "# Merge explanations with the original df\n",
    "df_with_explanations = df.join(explanations_df, how='left')\n",
    "\n",
    "# Display the DataFrame with explanations\n",
    "df_with_explanations.head()\n",
    "\n",
    "# Output the first explanation\n",
    "first_explanation = explanations_df.iloc[0]\n",
    "\n",
    "# Print the details\n",
    "print(\"Index:\", first_explanation['Index'])\n",
    "print(\"Prediction:\", first_explanation['Prediction'])\n",
    "print(\"Actual:\", first_explanation['Actual'])\n",
    "print(\"Explanation:\", first_explanation['Explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d574749",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbec898-b387-4aaf-96dd-88c5da1ee50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Explanation' column (Reason) from explanations_df to the original df\n",
    "# Load the application_record dataset\n",
    "data = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/application_record.csv\")\n",
    "\n",
    "# Load the credit_record dataset\n",
    "record = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/credit_record.csv\")\n",
    "# Find the first account open month for each user\n",
    "begin_month = record.loc[record.groupby(\"ID\")[\"MONTHS_BALANCE\"].idxmin()]\n",
    "begin_month = begin_month.rename(columns={\"MONTHS_BALANCE\": \"begin_month\"})\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(data, begin_month, how=\"left\", on=\"ID\")\n",
    "print(\"Datasets loaded and merged successfully.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53776ac9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the 'Explanation' column (Reason) from explanations_df to the original df\n",
    "df['Reason'] = explanations_df['Explanation']\n",
    "\n",
    "# Save the updated dataframe with the new column as a CSV file\n",
    "df.to_csv('/opt/notebooks/Chatbot-Credit-Card/backend/dataset/target-augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3252c3-978e-41da-98d4-1400e36650eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of explanations: {len(explanations)}\")\n",
    "print(f\"Number of rows in df: {df.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "/opt/notebooks/Chatbot-Credit-Card/backend/notebooks/Pre-processing-Dataset1.ipynb",
   "output_path": "/opt/notebooks/Chatbot-Credit-Card/backend/notebooks/Pre-processing-Dataset1.ipynb",
   "parameters": {},
   "start_time": "2024-11-04T15:49:15.703783",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
