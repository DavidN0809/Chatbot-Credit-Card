{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Married</th>\n",
       "      <th>BankCustomer</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>YearsEmployed</th>\n",
       "      <th>PriorDefault</th>\n",
       "      <th>Employed</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DriversLicense</th>\n",
       "      <th>Citizen</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Income</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Black</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>White</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByOtherMeans</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Energy</td>\n",
       "      <td>White</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>200</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Latino</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ConsumerStaples</td>\n",
       "      <td>White</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>280</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Black</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ByBirth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender    Age    Debt  Married  BankCustomer         Industry Ethnicity  \\\n",
       "0         1  30.83   0.000        1             1      Industrials     White   \n",
       "1         0  58.67   4.460        1             1        Materials     Black   \n",
       "2         0  24.50   0.500        1             1        Materials     Black   \n",
       "3         1  27.83   1.540        1             1      Industrials     White   \n",
       "4         1  20.17   5.625        1             1      Industrials     White   \n",
       "..      ...    ...     ...      ...           ...              ...       ...   \n",
       "685       1  21.08  10.085        0             0        Education     Black   \n",
       "686       0  22.67   0.750        1             1           Energy     White   \n",
       "687       0  25.25  13.500        0             0       Healthcare    Latino   \n",
       "688       1  17.92   0.205        1             1  ConsumerStaples     White   \n",
       "689       1  35.00   3.375        1             1           Energy     Black   \n",
       "\n",
       "     YearsEmployed  PriorDefault  Employed  CreditScore  DriversLicense  \\\n",
       "0             1.25             1         1            1               0   \n",
       "1             3.04             1         1            6               0   \n",
       "2             1.50             1         0            0               0   \n",
       "3             3.75             1         1            5               1   \n",
       "4             1.71             1         0            0               0   \n",
       "..             ...           ...       ...          ...             ...   \n",
       "685           1.25             0         0            0               0   \n",
       "686           2.00             0         1            2               1   \n",
       "687           2.00             0         1            1               1   \n",
       "688           0.04             0         0            0               0   \n",
       "689           8.29             0         0            0               1   \n",
       "\n",
       "          Citizen  ZipCode  Income  Approved  \n",
       "0         ByBirth      202       0         1  \n",
       "1         ByBirth       43     560         1  \n",
       "2         ByBirth      280     824         1  \n",
       "3         ByBirth      100       3         1  \n",
       "4    ByOtherMeans      120       0         1  \n",
       "..            ...      ...     ...       ...  \n",
       "685       ByBirth      260       0         0  \n",
       "686       ByBirth      200     394         0  \n",
       "687       ByBirth      200       1         0  \n",
       "688       ByBirth      280     750         0  \n",
       "689       ByBirth        0       0         0  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\n",
    "#https://www.kaggle.com/datasets/alexisbcook/synthetic-credit-card-approval\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend//dataset/Cleaned-CC-Data/clean_dataset.csv\")\n",
    "df\n",
    "\n",
    "# path = kagglehub.dataset_download(\"rikdifos/credit-card-approval-prediction\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# current_working_dir = os.getcwd()\n",
    "\n",
    "# os.system(f\"mv {path} {destination_path}\")\n",
    "\n",
    "# csv_files = [f for f in os.listdir(destination_path) if f.endswith('.csv')]\n",
    "# dataframes = {}\n",
    "# print(f\"Dataset moved to: {destination_path}\")\n",
    "\n",
    "# csv_files = [f for f in os.listdir(destination_path) if f.endswith('.csv')]\n",
    "\n",
    "# # Dynamically load each CSV into its own DataFrame using globals()\n",
    "# for csv_file in csv_files:\n",
    "#     file_path = os.path.join(destination_path, csv_file)\n",
    "#     df_name = \"df_\" + os.path.splitext(csv_file)[0]  # Create a name for the DataFrame (e.g., df_credit_record)\n",
    "    \n",
    "#     # Dynamically assign the DataFrame to a variable using globals()\n",
    "#     globals()[df_name] = pd.read_csv(file_path)\n",
    "    \n",
    "#     print(f\"Loaded {csv_file} into DataFrame: {df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Categorical Columns: ['Industry', 'Ethnicity', 'Citizen', 'Gender', 'Married', 'BankCustomer', 'PriorDefault', 'Employed', 'DriversLicense', 'Approved']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "# Automatically identify categorical columns from the dataframe based on data types\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Identify potential categorical columns stored as numbers by checking unique values\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 10 and col not in categorical_cols:  # Arbitrary threshold of < 10 unique values\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "# Display identified categorical columns\n",
    "print(f\"Identified Categorical Columns: {categorical_cols}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry:\n",
      "\u001b[32m'Industry' is a 'Good Predictor'\n",
      "p_val = 3.502987066102042e-15\n",
      "\n",
      "Ethnicity:\n",
      "\u001b[32m'Ethnicity' is a 'Good Predictor'\n",
      "p_val = 1.823665654934685e-08\n",
      "\n",
      "Citizen:\n",
      "\u001b[32m'Citizen' is a 'Good Predictor'\n",
      "p_val = 0.010094291370456362\n",
      "\n",
      "Gender:\n",
      "\u001b[31m'Gender' is a 'bad Predictor'\n",
      "p_val = 0.44723087514133186\n",
      "\n",
      "Married:\n",
      "\u001b[32m'Married' is a 'Good Predictor'\n",
      "p_val = 2.100231920165588e-06\n",
      "\n",
      "BankCustomer:\n",
      "\u001b[32m'BankCustomer' is a 'Good Predictor'\n",
      "p_val = 6.91661320541803e-07\n",
      "\n",
      "PriorDefault:\n",
      "\u001b[32m'PriorDefault' is a 'Good Predictor'\n",
      "p_val = 7.298530125411298e-80\n",
      "\n",
      "Employed:\n",
      "\u001b[32m'Employed' is a 'Good Predictor'\n",
      "p_val = 2.227269345312281e-33\n",
      "\n",
      "DriversLicense:\n",
      "\u001b[31m'DriversLicense' is a 'bad Predictor'\n",
      "p_val = 0.4061341323141693\n",
      "\n",
      "Approved:\n",
      "\u001b[32m'Approved' is a 'Good Predictor'\n",
      "p_val = 4.469841378183071e-152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store bad predictors\n",
    "bad_predictors = []\n",
    "\n",
    "# You can change the threshold for what is considered a \"bad predictor\"\n",
    "p_value_threshold = 0.05  # Adjust this if needed\n",
    "\n",
    "# Evaluate each categorical column using chi-squared test\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}:\")\n",
    "    \n",
    "    # Perform chi-squared test\n",
    "    a = np.array(pd.crosstab(df['Approved'], df[col]))\n",
    "    stats, p, dof, _ = chi2_contingency(a, correction=False)\n",
    "    \n",
    "    if p > p_value_threshold:\n",
    "        print(Fore.RED + f\"'{col}' is a 'bad Predictor'\")\n",
    "        print(f\"p_val = {p}\\n\")\n",
    "        bad_predictors.append(col)  # Append the bad predictor to the list\n",
    "    else:\n",
    "        print(Fore.GREEN + f\"'{col}' is a 'Good Predictor'\")\n",
    "        print(f\"p_val = {p}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped bad predictors: ['Gender', 'DriversLicense']\n",
      "     Age   Debt  Married  BankCustomer     Industry Ethnicity  YearsEmployed  \\\n",
      "0  30.83  0.000        1             1  Industrials     White           1.25   \n",
      "1  58.67  4.460        1             1    Materials     Black           3.04   \n",
      "2  24.50  0.500        1             1    Materials     Black           1.50   \n",
      "3  27.83  1.540        1             1  Industrials     White           3.75   \n",
      "4  20.17  5.625        1             1  Industrials     White           1.71   \n",
      "\n",
      "   PriorDefault  Employed  CreditScore       Citizen  ZipCode  Income  \\\n",
      "0             1         1            1       ByBirth      202       0   \n",
      "1             1         1            6       ByBirth       43     560   \n",
      "2             1         0            0       ByBirth      280     824   \n",
      "3             1         1            5       ByBirth      100       3   \n",
      "4             1         0            0  ByOtherMeans      120       0   \n",
      "\n",
      "   Approved  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n"
     ]
    }
   ],
   "source": [
    "# Automatically drop bad predictors\n",
    "df.drop(bad_predictors, axis=1, inplace=True)\n",
    "\n",
    "# Print the final dataframe structure after dropping\n",
    "print(f\"Dropped bad predictors: {bad_predictors}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove the target variable from the list of features if present\n",
    "if 'Approved' in categorical_cols:\n",
    "    categorical_cols.remove('Approved')\n",
    "if 'Approved' in numerical_cols:\n",
    "    numerical_cols.remove('Approved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of the columns:\n",
      "Age              float64\n",
      "Debt             float64\n",
      "Married            int64\n",
      "BankCustomer       int64\n",
      "Industry          object\n",
      "Ethnicity         object\n",
      "YearsEmployed    float64\n",
      "PriorDefault       int64\n",
      "Employed           int64\n",
      "CreditScore        int64\n",
      "Citizen           object\n",
      "ZipCode            int64\n",
      "Income             int64\n",
      "Approved           int64\n",
      "dtype: object\n",
      "\n",
      "Categorical columns identified:\n",
      "['Industry', 'Ethnicity', 'Citizen']\n"
     ]
    }
   ],
   "source": [
    "print(\"Data types of the columns:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nCategorical columns identified:\")\n",
    "print(categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in categorical columns after encoding:\n",
      "Industry: [ 7  9  0 12  8  5  4 10 13  1  3  2  6 11]\n",
      "Ethnicity: [4 1 0 2 3]\n",
      "Citizen: [0 1 2]\n",
      "\n",
      "Data types of the columns after encoding:\n",
      "Age              float64\n",
      "Debt             float64\n",
      "Married            int64\n",
      "BankCustomer       int64\n",
      "Industry           int64\n",
      "Ethnicity          int64\n",
      "YearsEmployed    float64\n",
      "PriorDefault       int64\n",
      "Employed           int64\n",
      "CreditScore        int64\n",
      "Citizen            int64\n",
      "ZipCode            int64\n",
      "Income             int64\n",
      "Approved           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Initialize LabelEncoders for categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # Store the encoder for future use (e.g., inverse_transform)\n",
    "\n",
    "print(\"Unique values in categorical columns after encoding:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")\n",
    "print(\"\\nData types of the columns after encoding:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (414, 13) (414,)\n",
      "Validation set: (138, 13) (138,)\n",
      "Test set: (138, 13) (138,)\n"
     ]
    }
   ],
   "source": [
    "# For preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# For splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Approved', axis=1)\n",
    "y = df['Approved']\n",
    "\n",
    "# Split the data into training, testing, and validation sets\n",
    "# First split: train + validate and test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: train and validate\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Print the shapes of the resulting splits\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, ccp_alpha=0.01),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results = {}\n",
    "\n",
    "# Iterate over each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model using the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test and validation data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # For AUC-ROC, we need the probability scores for the positive class\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    y_val_prob = model.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_test_prob) if y_test_prob is not None else None\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "    val_r2 = r2_score(y_val, y_val_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_auc = roc_auc_score(y_val, y_val_prob) if y_val_prob is not None else None\n",
    "    \n",
    "    # Store the evaluation results\n",
    "    results[model_name] = {\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Test AUC\": test_auc,\n",
    "        \"Validation Accuracy\": val_accuracy,\n",
    "        \"Validation AUC\": val_auc,\n",
    "        \"Test MAE\": test_mae,\n",
    "        \"Validation MAE\": val_mae,\n",
    "        \"Test R2\": test_r2,\n",
    "        \"Validation R2\": val_r2\n",
    "    }\n",
    "\n",
    "# Display the raw numbers\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name} Evaluation:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model based on the highest test accuracy\n",
    "best_model = max(results, key=lambda x: results[x][\"Test Accuracy\"])\n",
    "best_accuracy = results[best_model][\"Test Accuracy\"]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Access the trained model object\n",
    "best_model_name = best_model  # 'Random Forest' as per your previous code\n",
    "best_model = models[best_model_name]  # This is the trained Random Forest model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings from LIME (optional)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define the LimeTabularExplainer\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['Not Approved', 'Approved'],\n",
    "    mode='classification'\n",
    ")\n",
    "# Initialize an empty list to store explanations\n",
    "explanations = []\n",
    "\n",
    "\n",
    "# Suppress the specific warnings from the deprecated usage in lime\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Define the LimeTabularExplainer\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=['Not Approved', 'Approved'],  # Adjust according to your dataset\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Pick a single instance from the test set to explain for testing\n",
    "i = 0  # Index of the instance to explain\n",
    "\n",
    "exp = lime_explainer.explain_instance(X_test.iloc[i], best_model.predict_proba)\n",
    "\n",
    "# Display the explanation for the instance\n",
    "exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Suppress specific warnings from LIME (optional)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Function to extract the feature name from the LIME explanation\n",
    "def extract_feature_name(feature_str):\n",
    "    # Split on '<', '>', '=', '!=', etc., and take the first part\n",
    "    split_symbols = ['<=', '>=', '<', '>', '!=', '=']\n",
    "    for symbol in split_symbols:\n",
    "        if symbol in feature_str:\n",
    "            feature_name = feature_str.split(symbol)[0].strip()\n",
    "            break\n",
    "    else:\n",
    "        feature_name = feature_str.strip()\n",
    "    # Remove any numeric values\n",
    "    feature_name = re.sub(r'[0-9]+', '', feature_name)\n",
    "    # Remove any non-alphanumeric characters except spaces\n",
    "    feature_name = re.sub(r'[^A-Za-z0-9 ]+', '', feature_name)\n",
    "    # Replace multiple spaces with a single space\n",
    "    feature_name = re.sub(r'\\s+', ' ', feature_name)\n",
    "    return feature_name.strip()\n",
    "\n",
    "# Initialize the LimeTabularExplainer for the entire feature dataset `X`\n",
    "lime_explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X),\n",
    "    feature_names=X.columns,\n",
    "    class_names=['Not Approved', 'Approved'],  # Adjust according to your dataset\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store explanations\n",
    "explanations = []\n",
    "\n",
    "# Loop over the instances in the entire feature dataset `X`\n",
    "for idx, instance in X.iterrows():\n",
    "    # Get the model's prediction\n",
    "    prediction = best_model.predict(instance.values.reshape(1, -1))[0]\n",
    "    # Get the actual label from `y`\n",
    "    actual_label = y.loc[idx]\n",
    "    # Generate LIME explanation\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        data_row=instance,\n",
    "        predict_fn=best_model.predict_proba,\n",
    "        num_features=len(X.columns)  # Consider all features\n",
    "    )\n",
    "    # Get the list of (feature, contribution) pairs\n",
    "    explanation_list = exp.as_list()\n",
    "\n",
    "    # Determine the decision (Approved or Denied)\n",
    "    decision = 'Approved' if prediction == 1 else 'Denied'\n",
    "\n",
    "    # Collect features contributing to the predicted class\n",
    "    features_contributing = []\n",
    "    for feature, weight in explanation_list:\n",
    "        # For the predicted class, collect all features regardless of weight\n",
    "        if (prediction == 1 and weight > 0) or (prediction == 0 and weight < 0):\n",
    "            feature_name = extract_feature_name(feature)\n",
    "            if feature_name and feature_name not in features_contributing:\n",
    "                features_contributing.append(feature_name)\n",
    "\n",
    "    # Construct the explanation text\n",
    "    if features_contributing:\n",
    "        explanation_text = f\"This application was {decision.lower()} due to \" + \", \".join(features_contributing) + \".\"\n",
    "    else:\n",
    "        explanation_text = f\"This application was {decision.lower()}.\"\n",
    "\n",
    "    # Append the explanation and related information\n",
    "    explanations.append({\n",
    "        'Index': idx,\n",
    "        'Prediction': decision,\n",
    "        'Actual': 'Approved' if actual_label == 1 else 'Denied',\n",
    "        'Explanation': explanation_text\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the explanations to a DataFrame\n",
    "explanations_df = pd.DataFrame(explanations)\n",
    "\n",
    "# Output the first explanation\n",
    "first_explanation = explanations_df.iloc[0]\n",
    "\n",
    "# Print the details\n",
    "print(\"Index:\", first_explanation['Index'])\n",
    "print(\"Prediction:\", first_explanation['Prediction'])\n",
    "print(\"Actual:\", first_explanation['Actual'])\n",
    "print(\"Explanation:\", first_explanation['Explanation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reimport data due to earlier augmentation\n",
    "df = pd.read_csv(\"../dataset/Cleaned-CC-Data/clean_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'Explanation' column (Reason) from explanations_df to the original df\n",
    "df['Reason'] = explanations_df['Explanation']\n",
    "\n",
    "# Save the updated dataframe with the new column as a CSV file\n",
    "df.to_csv('../dataset/cleaned-augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
