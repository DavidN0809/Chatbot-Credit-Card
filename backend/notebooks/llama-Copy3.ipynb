{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666d56dd-a534-4907-8c32-e3d94ab3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "\n",
    "from accelerate import infer_auto_device_map\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae67b3f7-d781-4d5c-a92c-dbf4bbdf463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login --token key   \n",
    "# wandb login --relogin key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c44e03d-c5a3-4d95-9fe1-b32659ffeeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded and merged successfully.\n",
      "Approval status merged successfully.\n",
      "Preprocessing completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type  Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment          32                      4542.0           1.0   \n",
       "1   Rented apartment          32                      4542.0           1.0   \n",
       "2  House / apartment          58                      1134.0           1.0   \n",
       "3  House / apartment          52                      3051.0           1.0   \n",
       "4  House / apartment          52                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \n",
       "0         1.0    0.0    0.0             NaN          2.0         1  \n",
       "1         1.0    0.0    0.0             NaN          2.0         1  \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1  \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1  \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\n",
    "# Load the application_record dataset\n",
    "data = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/application_record.csv\")\n",
    "# Load the credit_record dataset\n",
    "record = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/credit_record.csv\")\n",
    "# Find the first account open month for each user\n",
    "begin_month = record.loc[record.groupby(\"ID\")[\"MONTHS_BALANCE\"].idxmin()]\n",
    "begin_month = begin_month.rename(columns={\"MONTHS_BALANCE\": \"begin_month\"})\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(data, begin_month, how=\"left\", on=\"ID\")\n",
    "print(\"Datasets loaded and merged successfully.\")\n",
    "# Define approval logic based on multiple criteria\n",
    "def determine_approval(row):\n",
    "    # Define custom approval logic\n",
    "    if row[\"STATUS\"] in [\"0\", \"1\", \"C\", \"X\"]:  # Good credit status\n",
    "            return 1  # Approved\n",
    "    return 0  # Default to denial if STATUS is bad or missing\n",
    "\n",
    "# Apply logic to determine approval (filling missing STATUS values first)\n",
    "record[\"STATUS\"] = record[\"STATUS\"].fillna(\"X\")  # Handle missing values\n",
    "record[\"Approved\"] = record.apply(determine_approval, axis=1)\n",
    "# Aggregate approval status for each ID (disapproval if any ID has disqualifying criteria)\n",
    "approval_status = record.groupby(\"ID\")[\"Approved\"].min().reset_index()\n",
    "# Merge approval status back into the main dataset, avoiding \"_x\" and \"_y\" columns\n",
    "df = pd.merge(data, approval_status, how=\"left\", on=\"ID\")\n",
    "df[\"Approved\"] = df[\"Approved\"].fillna(0).astype(int)  # Fill missing approvals as denial\n",
    "print(\"Approval status merged successfully.\")\n",
    "# Preprocess the 'DAYS_BIRTH' column to convert days to years\n",
    "df['DAYS_BIRTH'] = (-df['DAYS_BIRTH'] // 365).fillna(0).astype(int)\n",
    "df.drop(columns=['ID'], inplace=True)\n",
    "# Preprocess the 'DAYS_EMPLOYED' column to get absolute values and handle unemployment\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "# Handle missing or infinite values in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())  # Fill NaN with median values\n",
    "print(\"Preprocessing completed successfully.\")\n",
    "\n",
    "# Define the feature mapping dictionary\n",
    "feature_mapping = {\n",
    "    'CODE_GENDER': 'Gender',\n",
    "    'FLAG_OWN_CAR': 'Car Ownership',\n",
    "    'FLAG_OWN_REALTY': 'Property Ownership',\n",
    "    'CNT_CHILDREN': 'Number of Children',\n",
    "    'AMT_INCOME_TOTAL': 'Annual Income',\n",
    "    'NAME_INCOME_TYPE': 'Income Category',\n",
    "    'NAME_EDUCATION_TYPE': 'Education Level',\n",
    "    'NAME_FAMILY_STATUS': 'Marital Status',\n",
    "    'NAME_HOUSING_TYPE': 'Housing Type',\n",
    "    'DAYS_BIRTH': 'Age (Days)',\n",
    "    'DAYS_EMPLOYED': 'Employment Duration (Days)',\n",
    "    'FLAG_MOBIL': 'Mobile Phone',\n",
    "    'FLAG_WORK_PHONE': 'Work Phone',\n",
    "    'FLAG_PHONE': 'Phone',\n",
    "    'FLAG_EMAIL': 'Email',\n",
    "    'OCCUPATION_TYPE': 'Occupation',\n",
    "    'CNT_FAM_MEMBERS': 'Family Size',\n",
    "    'STATUS': 'Credit Status'\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame using the mapping\n",
    "df.rename(columns=feature_mapping, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "df.head()\n",
    "df.rename(columns={'TARGET': 'Approved'}, inplace=True)\n",
    "# Display the first few rows to confirm the change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c9fc4d-7637-4dc9-b335-5733a304c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to -0.77, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Email, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denied</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was denied due to -1.62, Emai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction    Actual                                        Explanation\n",
       "0   Approved  Approved  This application was approved due to Employmen...\n",
       "1   Approved  Approved  This application was approved due to Employmen...\n",
       "2   Approved  Approved  This application was approved due to -0.77, Ma...\n",
       "3   Approved  Approved  This application was approved due to Email, -0...\n",
       "4     Denied  Approved  This application was denied due to -1.62, Emai..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_df = pd.read_csv('/opt/notebooks/Chatbot-Credit-Card/backend/dataset/explanations_df.csv')\n",
    "# explanation_df.drop(['Approved','Explanation'], axis=1, inplace=True)\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2540947f-ff72-40c0-8d27-7f310edb9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, -0.77, Marital Status, Work Phone, -0.15, Number of Children, -0.81, Family Size, Annual Income.\n"
     ]
    }
   ],
   "source": [
    "print(explanation_df['Explanation'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55a4c06-ecdb-437b-9a1f-d89d653d9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers and clean the Explanation column\n",
    "def clean_explanation(text):\n",
    "    return re.sub(r'[-+]?\\d*\\.\\d+|\\d+', '', text).replace(', ,', ',').replace(' ,', ',').strip(\", \")\n",
    "\n",
    "# Apply the cleaning function to the Explanation column\n",
    "explanation_df[\"Explanation\"] = explanation_df[\"Explanation\"].apply(clean_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3809e3a1-e7af-4f16-964f-39ceee20d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, Marital Status, Work Phone, Number of Children, Family Size, Annual Income.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to, Marital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Email, Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denied</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was denied due to, Email, Hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction    Actual                                        Explanation\n",
       "0   Approved  Approved  This application was approved due to Employmen...\n",
       "1   Approved  Approved  This application was approved due to Employmen...\n",
       "2   Approved  Approved  This application was approved due to, Marital ...\n",
       "3   Approved  Approved  This application was approved due to Email, Nu...\n",
       "4     Denied  Approved  This application was denied due to, Email, Hou..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame with the cleaned Explanation column\n",
    "print(explanation_df['Explanation'].iloc[0])\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f1cb95-f0a3-44d5-8df2-64849a0c0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'Age (Days)': 'Age (Years)'}, inplace=True)\n",
    "df.rename(columns={'Employment Duration' : 'Employment Duration (Days)'}, inplace=True)\n",
    "df['Age (Days)'] = df['Age (Days)'].astype(str) + \" years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ecd81d-edae-4d65-be32-13503fe03ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, Marital Status, Work Phone, Number of Children, Family Size, Annual Income.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to, Marital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email, Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to, Email, Hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type    Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                      4542.0           1.0   \n",
       "1   Rented apartment  32 years old                      4542.0           1.0   \n",
       "2  House / apartment  58 years old                      1134.0           1.0   \n",
       "3  House / apartment  52 years old                      3051.0           1.0   \n",
       "4  House / apartment  52 years old                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to, Marital ...  \n",
       "3  This application was approved due to Email, Nu...  \n",
       "4  This application was denied due to, Email, Hou...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine explanation_df and df based on index\n",
    "df['Reason'] = explanation_df['Explanation'].reset_index(drop=True)\n",
    "\n",
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa91600a-5b74-4c15-a021-811231791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically replace labels with row values\n",
    "def insert_numbers_dynamically(row):\n",
    "    reason = row['Reason']\n",
    "    \n",
    "    # Extract all parts of the reason where dynamic replacement is needed\n",
    "    labels = re.findall(r'([A-Za-z\\s()]+)', reason)\n",
    "    \n",
    "    for label in labels:\n",
    "        # Match the label to the corresponding column name\n",
    "        column_name = None\n",
    "        for col in df.columns:\n",
    "            # Normalize column names and labels for matching\n",
    "            normalized_col = re.sub(r'[\\s()]+', '', col).lower()\n",
    "            normalized_label = re.sub(r'[\\s()]+', '', label).lower()\n",
    "            \n",
    "            if normalized_col == normalized_label:\n",
    "                column_name = col\n",
    "                break\n",
    "        \n",
    "        if column_name and column_name in row:  # Ensure column exists in the DataFrame\n",
    "            # Replace the label with the corresponding value from the row\n",
    "            value = row[column_name]\n",
    "            # Ensure proper replacement in the text\n",
    "            reason = reason.replace(label, f\"{label.strip()} {value}\")\n",
    "    \n",
    "    return reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de84f6b-5383-4ddf-97bf-34a9e40bb3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to,Marital S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email,Num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to,Email 1.0,H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type    Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                      4542.0           1.0   \n",
       "1   Rented apartment  32 years old                      4542.0           1.0   \n",
       "2  House / apartment  58 years old                      1134.0           1.0   \n",
       "3  House / apartment  52 years old                      3051.0           1.0   \n",
       "4  House / apartment  52 years old                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to,Marital S...  \n",
       "3  This application was approved due to Email,Num...  \n",
       "4  This application was denied due to,Email 1.0,H...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each row in the DataFrame\n",
    "df['Reason'] = df.apply(insert_numbers_dynamically, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e326c282-2355-4055-ab40-42b98f101d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Years)</th>\n",
       "      <th>Employment Duration (Years)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>12.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>12.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to,Marital S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email,Num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to,Email 1.0,H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type   Age (Years)  Employment Duration (Years)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                        12.44           1.0   \n",
       "1   Rented apartment  32 years old                        12.44           1.0   \n",
       "2  House / apartment  58 years old                         3.11           1.0   \n",
       "3  House / apartment  52 years old                         8.36           1.0   \n",
       "4  House / apartment  52 years old                         8.36           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to,Marital S...  \n",
       "3  This application was approved due to Email,Num...  \n",
       "4  This application was denied due to,Email 1.0,H...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert \"Employment Duration (Days)\" to years in-place\n",
    "df[\"Employment Duration (Days)\"] = df[\"Employment Duration (Days)\"].apply(lambda x: round(x / 365.0, 2) if not pd.isna(x) else np.nan)\n",
    "df.rename(columns={\"Age (Days)\": \"Age (Years)\", \"Employment Duration (Days)\": \"Employment Duration (Years)\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e94d63b-b049-48ba-84c1-d4d546924bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Update the \"Reason\" column to match the new labels\n",
    "def update_reason(reason_text):\n",
    "    reason_text = reason_text.replace(\"Age (Days)\", \"Age (Years)\")\n",
    "    reason_text = reason_text.replace(\"Employment Duration (Days)\", \"Employment Duration (Years)\")\n",
    "    return reason_text\n",
    "\n",
    "df[\"Reason\"] = df[\"Reason\"].apply(update_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569a1958-db10-4301-bc49-20782c1b67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Years),Housing Type Rented apartment,Marital Status Civil marriage,Work Phone 1.0,Number of Children 0,Family Size 2.0,Annual Income 427500.0.\n"
     ]
    }
   ],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada571ee-ae3e-423c-a87e-e205a4ec3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plain_input_and_label(row):\n",
    "    # Generate the reasoning part of the label\n",
    "    reasoning_parts = [\n",
    "        f\"Gender: {'Male' if row['Gender'] == 'M' else 'Female'}\" if pd.notna(row.get('Gender')) else None,\n",
    "        f\"Age: {row['Age (Years)']} years old\" if pd.notna(row.get('Age (Years)')) else None,\n",
    "        f\"Car Ownership: {'Yes' if row['Car Ownership'] == 'Y' else 'No'}\" if pd.notna(row.get('Car Ownership')) else None,\n",
    "        f\"Property Ownership: {'Yes' if row['Property Ownership'] == 'Y' else 'No'}\" if pd.notna(row.get('Property Ownership')) else None,\n",
    "        f\"Number of Children: {int(row['Number of Children'])}\" if pd.notna(row.get('Number of Children')) else None,\n",
    "        f\"Annual Income: {row['Annual Income']}\" if pd.notna(row.get('Annual Income')) else None,\n",
    "        f\"Income Category: {row['Income Category']}\" if pd.notna(row.get('Income Category')) else None,\n",
    "        f\"Education Level: {row['Education Level']}\" if pd.notna(row.get('Education Level')) else None,\n",
    "        f\"Marital Status: {row['Marital Status']}\" if pd.notna(row.get('Marital Status')) else None,\n",
    "        f\"Housing Type: {row['Housing Type']}\" if pd.notna(row.get('Housing Type')) else None,\n",
    "        f\"Employment Duration: {row['Employment Duration (Years)']} years\" if pd.notna(row.get('Employment Duration (Years)')) else None,\n",
    "        f\"Mobile Phone: {'Yes' if row['Mobile Phone'] == 1 else 'No'}\" if pd.notna(row.get('Mobile Phone')) else None,\n",
    "        f\"Work Phone: {'Yes' if row['Work Phone'] == 1 else 'No'}\" if pd.notna(row.get('Work Phone')) else None,\n",
    "        f\"Email: {'Yes' if row['Email'] == 1 else 'No'}\" if pd.notna(row.get('Email')) else None,\n",
    "        f\"Family Size: {row['Family Size']}\" if pd.notna(row.get('Family Size')) else None,\n",
    "    ]\n",
    "    reasoning_text = \". \".join([part for part in reasoning_parts if part is not None])\n",
    "    label = f\"Approval Status: Approved. Reasoning: {reasoning_text}.\"\n",
    "\n",
    "    # Generate input in the same way\n",
    "    input_text = reasoning_text  # Reuse the reasoning parts for consistency\n",
    "\n",
    "    return input_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0abeeaf1-4853-44b1-a408-a792e8930dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row\n",
    "df[\"text\"], df[\"label\"] = zip(*df.apply(generate_plain_input_and_label, axis=1))\n",
    "\n",
    "# Keep only the required columns\n",
    "final_df = df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff6ece9c-dd0e-4dc8-85b1-7dd389f3a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "\n",
      "Approval Status: Approved. Reasoning: Gender: Male. Age: 32 years old years old. Car Ownership: Yes. Property Ownership: Yes. Number of Children: 0. Annual Income: 427500.0. Income Category: Working. Education Level: Higher education. Marital Status: Civil marriage. Housing Type: Rented apartment. Employment Duration: 12.44 years. Mobile Phone: Yes. Work Phone: Yes. Email: No. Family Size: 2.0.\n",
      "Input\n",
      "\n",
      "Gender: Male. Age: 32 years old years old. Car Ownership: Yes. Property Ownership: Yes. Number of Children: 0. Annual Income: 427500.0. Income Category: Working. Education Level: Higher education. Marital Status: Civil marriage. Housing Type: Rented apartment. Employment Duration: 12.44 years. Mobile Phone: Yes. Work Phone: Yes. Email: No. Family Size: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(\"Label\\n\")\n",
    "print(final_df['label'].iloc[0])\n",
    "print(\"Input\\n\")\n",
    "print(final_df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fea2c60-9ea8-4778-857f-172119c30ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the 'text' and 'label' columns\n",
    "final_df['text'] = final_df['text'].str.replace('years old years old', 'years old', regex=False)\n",
    "\n",
    "# Sample the dataset to 3000 rows for training efficiency\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd576e1a-c70a-4422-b1bb-74d46081fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ratios\n",
    "train_size = 0.8\n",
    "eval_size = 0.1\n",
    "\n",
    "# Calculate split indices\n",
    "train_end = int(train_size * len(df))\n",
    "eval_end = train_end + int(eval_size * len(df))\n",
    "\n",
    "# Split data\n",
    "X_train = df[:train_end]\n",
    "X_eval = df[train_end:eval_end]\n",
    "X_test = df[eval_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d0b5c3f-1c1d-4816-b013-06b3b49fc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt generation functions\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "Predict the credit card application status and provide reasoning.\n",
    "text: {data_point[\"text\"]}\n",
    "label: {data_point[\"label\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "Predict the credit card application status and provide reasoning.\n",
    "text: {data_point[\"text\"]}\n",
    "label: \n",
    "\"\"\".strip()\n",
    "\n",
    "# Apply to training and evaluation datasets\n",
    "X_train['text'] = X_train.apply(generate_prompt, axis=1)\n",
    "X_eval['text'] = X_eval.apply(generate_prompt, axis=1)\n",
    "\n",
    "# Apply to test dataset\n",
    "X_test_prompts = X_test.apply(generate_test_prompt, axis=1)\n",
    "y_true = X_test['label']\n",
    "X_test = pd.DataFrame(X_test_prompts, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "177572dc-e7b9-468e-8991-f2ad25170ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datasets\n",
    "train_data = Dataset.from_pandas(X_train[[\"text\"]])\n",
    "eval_data = Dataset.from_pandas(X_eval[[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8fda12e-9a63-44fd-9437-396f1f68ad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b42e2c21b81410d82ac9ac19b3d3bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data lengths:\n",
      "Dataset({\n",
      "    features: ['text', 'length'],\n",
      "    num_rows: 2400\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bc18e63fef46f3a3c1f16aa1a81bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval data lengths:\n",
      "Dataset({\n",
      "    features: ['text', 'length'],\n",
      "    num_rows: 300\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Display lengths of each entry in train_data\n",
    "train_lengths = train_data.map(lambda x: {\"length\": len(x[\"text\"])})\n",
    "print(\"Train data lengths:\")\n",
    "print(train_lengths)\n",
    "\n",
    "# Display lengths of each entry in eval_data\n",
    "eval_lengths = eval_data.map(lambda x: {\"length\": len(x[\"text\"])})\n",
    "print(\"Eval data lengths:\")\n",
    "print(eval_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf11fe0d-0692-48f9-b121-8c54746ecb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predict the credit card application status and provide reasoning.\\ntext: Gender: Female. Age: 32 years old years old. Car Ownership: Yes. Property Ownership: No. Number of Children: 0. Annual Income: 126000.0. Income Category: State servant. Education Level: Incomplete higher. Marital Status: Single / not married. Housing Type: House / apartment. Employment Duration: 14.26 years. Mobile Phone: Yes. Work Phone: Yes. Email: No. Family Size: 1.0\\nlabel: Approval Status: Approved. Reasoning: Gender: Female. Age: 32 years old years old. Car Ownership: Yes. Property Ownership: No. Number of Children: 0. Annual Income: 126000.0. Income Category: State servant. Education Level: Incomplete higher. Marital Status: Single / not married. Housing Type: House / apartment. Employment Duration: 14.26 years. Mobile Phone: Yes. Work Phone: Yes. Email: No. Family Size: 1.0.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00bfd4b8-02e8-4e74-8613-59934f551218",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-8b-Instruct/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64982e8-98c1-4e52-be3f-e0c349903a68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_model_name \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\n\u001b[1;32m      3\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      4\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     11\u001b[0m     base_model_name,\n\u001b[1;32m     12\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model_name = base_model\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\",\n",
    "    quantization_config=bnb_config, \n",
    "    max_memory={0: \"16GiB\", \"cpu\": \"30GiB\"},\n",
    "\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "396c7e21-e3bd-4358-8748-51b569e7dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    statuses = [\"Approved\", \"Denied\"]  # The statuses for prediction\n",
    "    \n",
    "    for i in tqdm(range(len(test))):\n",
    "        prompt = test.iloc[i][\"text\"]\n",
    "        \n",
    "        # Initialize the text-generation pipeline\n",
    "        pipe = pipeline(\n",
    "            task=\"text-generation\", \n",
    "            model=model, \n",
    "            tokenizer=tokenizer, \n",
    "            max_new_tokens=50,  # Increase to ensure reasoning is generated\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # Generate prediction\n",
    "        result = pipe(prompt)\n",
    "        generated_text = result[0]['generated_text']\n",
    "        \n",
    "        # Parse the output to extract status and reason\n",
    "        try:\n",
    "            # Extract 'label:' portion and split to get the prediction\n",
    "            answer = generated_text.split(\"label:\")[-1].strip()\n",
    "            \n",
    "            # Extract status (Approved/Denied)\n",
    "            status = None\n",
    "            for s in statuses:\n",
    "                if s.lower() in answer.lower():\n",
    "                    status = s\n",
    "                    break\n",
    "            \n",
    "            # Append the status and reasoning\n",
    "            if status:\n",
    "                y_pred.append({\n",
    "                    \"status\": status,\n",
    "                    \"reason\": answer  # Include full reasoning text\n",
    "                })\n",
    "            else:\n",
    "                y_pred.append({\n",
    "                    \"status\": \"Unknown\",\n",
    "                    \"reason\": answer\n",
    "                })\n",
    "        except Exception as e:\n",
    "            # Handle unexpected output format\n",
    "            y_pred.append({\n",
    "                \"status\": \"Error\",\n",
    "                \"reason\": f\"Parsing failed: {e}\"\n",
    "            })\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# # Example Usage\n",
    "# # Assuming `X_test` is your test DataFrame and `model`, `tokenizer` are already loaded\n",
    "# y_pred = predict(X_test, model, tokenizer)\n",
    "\n",
    "# # Print a few predictions to verify\n",
    "# for prediction in y_pred[:5]:\n",
    "#     print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08578ff9-a1d8-4ebc-b0c9-b9890e182aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# # Extract statuses from y_pred\n",
    "# statuses = [pred.get(\"status\", \"Unknown\") for pred in y_pred]\n",
    "\n",
    "# # Count occurrences of each status\n",
    "# status_counts = Counter(statuses)\n",
    "\n",
    "# # Display the counts\n",
    "# print(f\"Total counts by status:\")\n",
    "# print(f\"Approved: {status_counts['Approved']}\")\n",
    "# print(f\"Denied: {status_counts['Denied']}\")\n",
    "# print(f\"Unknown: {status_counts['Unknown']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c22e0293-1c01-469b-9c5e-df76f4d5e420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027b691583e2453e8b64a3a452dd744d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c90b966a894689a340a5becaabe3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_label_from_text(data_point):\n",
    "    try:\n",
    "        text = data_point[\"text\"]\n",
    "        if \"Approval Status:\" in text:\n",
    "            label_section = text.split(\"Approval Status:\")[1].strip()\n",
    "            return label_section.split(\".\")[0].strip()\n",
    "        else:\n",
    "            print(f\"Missing 'Approval Status:' in text: {text}\")\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing text: {text}, Error: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Add the 'status' column to train and evaluation datasets\n",
    "train_data = train_data.map(lambda x: {\"status\": extract_label_from_text(x)})\n",
    "eval_data = eval_data.map(lambda x: {\"status\": extract_label_from_text(x)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8697c589-9689-43f8-b453-27aad867dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    # Extract statuses from predictions\n",
    "    y_pred_statuses = []\n",
    "    for pred in y_pred:\n",
    "        if \"status\" in pred and pred[\"status\"] in [\"Approved\", \"Denied\", \"Unknown\"]:\n",
    "            y_pred_statuses.append(pred[\"status\"])\n",
    "        else:\n",
    "            y_pred_statuses.append(\"Unknown\")  # Default for malformed predictions\n",
    "\n",
    "    # Define label mapping (including \"Unknown\")\n",
    "    labels = [\"Approved\", \"Denied\", \"Unknown\"]\n",
    "    mapping = {label: idx for idx, label in enumerate(labels)}\n",
    "\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, -1)  # Map to -1 if not found\n",
    "\n",
    "    # Ensure lengths of y_true and y_pred match\n",
    "    if len(y_true) != len(y_pred_statuses):\n",
    "        raise ValueError(\"Length mismatch between y_true and y_pred.\")\n",
    "\n",
    "    # Map true and predicted labels\n",
    "    y_true_mapped = np.vectorize(map_func)(y_true)\n",
    "    y_pred_mapped = np.vectorize(map_func)(y_pred_statuses)\n",
    "\n",
    "    # Check for unmapped values\n",
    "    if -1 in y_true_mapped:\n",
    "        raise ValueError(\"Unmapped labels found in y_true. Ensure all labels are 'Approved', 'Denied', or 'Unknown'.\")\n",
    "    if -1 in y_pred_mapped:\n",
    "        raise ValueError(\"Unmapped labels found in y_pred. Ensure all predictions are 'Approved', 'Denied', or 'Unknown'.\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(\n",
    "        y_true=y_true_mapped, \n",
    "        y_pred=y_pred_mapped, \n",
    "        target_names=labels, \n",
    "        labels=list(range(len(labels)))\n",
    "    )\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(\n",
    "        y_true=y_true_mapped, \n",
    "        y_pred=y_pred_mapped, \n",
    "        labels=list(range(len(labels)))\n",
    "    )\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "# # Assertions to ensure valid inputs\n",
    "# assert all(label in [\"Approved\", \"Denied\", \"Unknown\"] for label in y_true), \"y_true contains unexpected labels!\"\n",
    "# assert all(\"status\" in pred for pred in y_pred), \"Some predictions are missing the 'status' key!\"\n",
    "# assert len(y_true) == len(y_pred), \"Mismatch in lengths of y_true and y_pred!\"\n",
    "\n",
    "# # Example usage with y_true and y_pred\n",
    "# y_true = X_test[\"status\"].tolist()\n",
    "# evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b2b2855-f47c-4f83-a261-9da488f7e564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['up_proj', 'v_proj', 'down_proj', 'o_proj', 'gate_proj', 'q_proj', 'k_proj']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "modules = find_all_linear_names(model)\n",
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98a3b972-faf9-4c42-967c-27832e1213bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a026a66d9d1c4c6993830bb8cc5696f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5bd5b8b1f543e5b4076458172b3ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir=\"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-fine-tuned-model\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules,\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=1,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,                         \n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"wandb\",                  # report metrics to w&b\n",
    "    eval_strategy=\"steps\",              # save checkpoint every epoch\n",
    "    eval_steps = 0.2\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=512,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "    \"add_special_tokens\": False,\n",
    "    \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f7ebd5a-86c1-4479-9f51-56ff7fa60a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdnicho26\u001b[0m (\u001b[33mdnicho26-university-of-north-carolina-at-charlotte\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec09140a5444d60978072eab3e532c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113046211054705, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/notebooks/Chatbot-Credit-Card/backend/notebooks/wandb/run-20241128_153244-etdytptk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface/runs/etdytptk' target=\"_blank\">/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-fine-tuned-model</a></strong> to <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface/runs/etdytptk' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/huggingface/runs/etdytptk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 385.12 MiB is free. Process 3491537 has 6.14 GiB memory in use. Process 3585902 has 9.36 GiB memory in use. Of the allocated memory 8.66 GiB is allocated by PyTorch, and 425.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:434\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 434\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/peft/peft_model.py:1644\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1643\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1210\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[0;32m-> 1210\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 385.12 MiB is free. Process 3491537 has 6.14 GiB memory in use. Process 3585902 has 9.36 GiB memory in use. Of the allocated memory 8.66 GiB is allocated by PyTorch, and 425.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69535db7-2fdd-4953-b830-466b9b7e3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f0556-630d-48a7-9baf-2b55b9b45303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418e10a-b0af-46c3-ba8b-7d020b5cbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc899c4f-dcfd-4231-b0bd-da2a08f2b277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
