{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d56dd-a534-4907-8c32-e3d94ab3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae67b3f7-d781-4d5c-a92c-dbf4bbdf463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login --token key   \n",
    "# wandb login --relogin key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44e03d-c5a3-4d95-9fe1-b32659ffeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\n",
    "# Load the application_record dataset\n",
    "data = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/application_record.csv\")\n",
    "# Load the credit_record dataset\n",
    "record = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/credit_record.csv\")\n",
    "# Find the first account open month for each user\n",
    "begin_month = record.loc[record.groupby(\"ID\")[\"MONTHS_BALANCE\"].idxmin()]\n",
    "begin_month = begin_month.rename(columns={\"MONTHS_BALANCE\": \"begin_month\"})\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(data, begin_month, how=\"left\", on=\"ID\")\n",
    "print(\"Datasets loaded and merged successfully.\")\n",
    "# Define approval logic based on multiple criteria\n",
    "def determine_approval(row):\n",
    "    # Define custom approval logic\n",
    "    if row[\"STATUS\"] in [\"0\", \"1\", \"C\", \"X\"]:  # Good credit status\n",
    "            return 1  # Approved\n",
    "    return 0  # Default to denial if STATUS is bad or missing\n",
    "\n",
    "# Apply logic to determine approval (filling missing STATUS values first)\n",
    "record[\"STATUS\"] = record[\"STATUS\"].fillna(\"X\")  # Handle missing values\n",
    "record[\"Approved\"] = record.apply(determine_approval, axis=1)\n",
    "# Aggregate approval status for each ID (disapproval if any ID has disqualifying criteria)\n",
    "approval_status = record.groupby(\"ID\")[\"Approved\"].min().reset_index()\n",
    "# Merge approval status back into the main dataset, avoiding \"_x\" and \"_y\" columns\n",
    "df = pd.merge(data, approval_status, how=\"left\", on=\"ID\")\n",
    "df[\"Approved\"] = df[\"Approved\"].fillna(0).astype(int)  # Fill missing approvals as denial\n",
    "print(\"Approval status merged successfully.\")\n",
    "# Preprocess the 'DAYS_BIRTH' column to convert days to years\n",
    "df['DAYS_BIRTH'] = (-df['DAYS_BIRTH'] // 365).fillna(0).astype(int)\n",
    "df.drop(columns=['ID'], inplace=True)\n",
    "# Preprocess the 'DAYS_EMPLOYED' column to get absolute values and handle unemployment\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "# Handle missing or infinite values in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())  # Fill NaN with median values\n",
    "print(\"Preprocessing completed successfully.\")\n",
    "\n",
    "# Define the feature mapping dictionary\n",
    "feature_mapping = {\n",
    "    'CODE_GENDER': 'Gender',\n",
    "    'FLAG_OWN_CAR': 'Car Ownership',\n",
    "    'FLAG_OWN_REALTY': 'Property Ownership',\n",
    "    'CNT_CHILDREN': 'Number of Children',\n",
    "    'AMT_INCOME_TOTAL': 'Annual Income',\n",
    "    'NAME_INCOME_TYPE': 'Income Category',\n",
    "    'NAME_EDUCATION_TYPE': 'Education Level',\n",
    "    'NAME_FAMILY_STATUS': 'Marital Status',\n",
    "    'NAME_HOUSING_TYPE': 'Housing Type',\n",
    "    'DAYS_BIRTH': 'Age (Days)',\n",
    "    'DAYS_EMPLOYED': 'Employment Duration (Days)',\n",
    "    'FLAG_MOBIL': 'Mobile Phone',\n",
    "    'FLAG_WORK_PHONE': 'Work Phone',\n",
    "    'FLAG_PHONE': 'Phone',\n",
    "    'FLAG_EMAIL': 'Email',\n",
    "    'OCCUPATION_TYPE': 'Occupation',\n",
    "    'CNT_FAM_MEMBERS': 'Family Size',\n",
    "    'STATUS': 'Credit Status'\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame using the mapping\n",
    "df.rename(columns=feature_mapping, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "df.head()\n",
    "df.rename(columns={'TARGET': 'Approved'}, inplace=True)\n",
    "# Display the first few rows to confirm the change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9fc4d-7637-4dc9-b335-5733a304c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_df = pd.read_csv('/opt/notebooks/Chatbot-Credit-Card/backend/dataset/explanations_df.csv')\n",
    "# explanation_df.drop(['Approved','Explanation'], axis=1, inplace=True)\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540947f-ff72-40c0-8d27-7f310edb9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(explanation_df['Explanation'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a4c06-ecdb-437b-9a1f-d89d653d9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers and clean the Explanation column\n",
    "def clean_explanation(text):\n",
    "    return re.sub(r'[-+]?\\d*\\.\\d+|\\d+', '', text).replace(', ,', ',').replace(' ,', ',').strip(\", \")\n",
    "\n",
    "# Apply the cleaning function to the Explanation column\n",
    "explanation_df[\"Explanation\"] = explanation_df[\"Explanation\"].apply(clean_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809e3a1-e7af-4f16-964f-39ceee20d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with the cleaned Explanation column\n",
    "print(explanation_df['Explanation'].iloc[0])\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1cb95-f0a3-44d5-8df2-64849a0c0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'Age (Days)': 'Age (Years)'}, inplace=True)\n",
    "df.rename(columns={'Employment Duration' : 'Employment Duration (Days)'}, inplace=True)\n",
    "df['Age (Days)'] = df['Age (Days)'].astype(str) + \" years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ecd81d-edae-4d65-be32-13503fe03ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine explanation_df and df based on index\n",
    "df['Reason'] = explanation_df['Explanation'].reset_index(drop=True)\n",
    "\n",
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91600a-5b74-4c15-a021-811231791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically replace labels with row values\n",
    "def insert_numbers_dynamically(row):\n",
    "    reason = row['Reason']\n",
    "    \n",
    "    # Extract all parts of the reason where dynamic replacement is needed\n",
    "    labels = re.findall(r'([A-Za-z\\s()]+)', reason)\n",
    "    \n",
    "    for label in labels:\n",
    "        # Match the label to the corresponding column name\n",
    "        column_name = None\n",
    "        for col in df.columns:\n",
    "            # Normalize column names and labels for matching\n",
    "            normalized_col = re.sub(r'[\\s()]+', '', col).lower()\n",
    "            normalized_label = re.sub(r'[\\s()]+', '', label).lower()\n",
    "            \n",
    "            if normalized_col == normalized_label:\n",
    "                column_name = col\n",
    "                break\n",
    "        \n",
    "        if column_name and column_name in row:  # Ensure column exists in the DataFrame\n",
    "            # Replace the label with the corresponding value from the row\n",
    "            value = row[column_name]\n",
    "            # Ensure proper replacement in the text\n",
    "            reason = reason.replace(label, f\"{label.strip()} {value}\")\n",
    "    \n",
    "    return reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de84f6b-5383-4ddf-97bf-34a9e40bb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row in the DataFrame\n",
    "df['Reason'] = df.apply(insert_numbers_dynamically, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326c282-2355-4055-ab40-42b98f101d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Employment Duration (Days)\" to years in-place\n",
    "df[\"Employment Duration (Days)\"] = df[\"Employment Duration (Days)\"].apply(lambda x: round(x / 365.0, 2) if not pd.isna(x) else np.nan)\n",
    "df.rename(columns={\"Age (Days)\": \"Age (Years)\", \"Employment Duration (Days)\": \"Employment Duration (Years)\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94d63b-b049-48ba-84c1-d4d546924bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Update the \"Reason\" column to match the new labels\n",
    "def update_reason(reason_text):\n",
    "    reason_text = reason_text.replace(\"Age (Days)\", \"Age (Years)\")\n",
    "    reason_text = reason_text.replace(\"Employment Duration (Days)\", \"Employment Duration (Years)\")\n",
    "    return reason_text\n",
    "\n",
    "df[\"Reason\"] = df[\"Reason\"].apply(update_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a1958-db10-4301-bc49-20782c1b67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e67b6-5fbb-4f4b-ab3c-d41b8f5a274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagged_input_and_label(row):\n",
    "    # Generate the reasoning part of the label using the same tags as input\n",
    "    reasoning_parts = [\n",
    "        f\"<gender> {'Male' if row['Gender'] == 'M' else 'Female'} </gender>\" if pd.notna(row.get('Gender')) else None,\n",
    "        f\"<age> {row['Age (Years)']} years old </age>\" if pd.notna(row.get('Age (Years)')) else None,\n",
    "        f\"<car_ownership> {'yes' if row['Car Ownership'] == 'Y' else 'no'} </car_ownership>\" if pd.notna(row.get('Car Ownership')) else None,\n",
    "        f\"<property_ownership> {'yes' if row['Property Ownership'] == 'Y' else 'no'} </property_ownership>\" if pd.notna(row.get('Property Ownership')) else None,\n",
    "        f\"<number_of_children> {int(row['Number of Children'])} </number_of_children>\" if pd.notna(row.get('Number of Children')) else None,\n",
    "        f\"<annual_income> {row['Annual Income']} </annual_income>\" if pd.notna(row.get('Annual Income')) else None,\n",
    "        f\"<income_category> {row['Income Category']} </income_category>\" if pd.notna(row.get('Income Category')) else None,\n",
    "        f\"<education_level> {row['Education Level']} </education_level>\" if pd.notna(row.get('Education Level')) else None,\n",
    "        f\"<marital_status> {row['Marital Status']} </marital_status>\" if pd.notna(row.get('Marital Status')) else None,\n",
    "        f\"<housing_type> {row['Housing Type']} </housing_type>\" if pd.notna(row.get('Housing Type')) else None,\n",
    "        f\"<employment_duration> {row['Employment Duration (Years)']} years </employment_duration>\" if pd.notna(row.get('Employment Duration (Years)')) else None,\n",
    "        f\"<mobile_phone> {'yes' if row['Mobile Phone'] == 1 else 'no'} </mobile_phone>\" if pd.notna(row.get('Mobile Phone')) else None,\n",
    "        f\"<work_phone> {'yes' if row['Work Phone'] == 1 else 'no'} </work_phone>\" if pd.notna(row.get('Work Phone')) else None,\n",
    "        f\"<email> {'yes' if row['Email'] == 1 else 'no'} </email>\" if pd.notna(row.get('Email')) else None,\n",
    "        f\"<family_size> {row['Family Size']} </family_size>\" if pd.notna(row.get('Family Size')) else None,\n",
    "    ]\n",
    "    reasoning_text = \" \".join([part for part in reasoning_parts if part is not None])\n",
    "    label = f\"<start_label> <approval_status> Approved </approval_status> <reasoning> {reasoning_text} </reasoning> <end_label>\"\n",
    "\n",
    "    # Generate input in the same way\n",
    "    input_parts = reasoning_parts  # Reuse the reasoning parts for consistency\n",
    "    input_text = \" \".join([part for part in input_parts if part is not None])\n",
    "    input_section = f\"<start_input> {input_text} <end_input>\"\n",
    "\n",
    "    return input_section, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4239c25-2bfb-43f6-a7c5-01b023d7acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row\n",
    "df[\"text\"], df[\"label\"] = zip(*df.apply(generate_tagged_input_and_label, axis=1))\n",
    "\n",
    "# Keep only the required columns\n",
    "final_df = df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c88087-3265-4990-9b80-2efbd8b1432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(\"Label\\n\")\n",
    "print(final_df['label'].iloc[0])\n",
    "print(\"Input\\n\")\n",
    "print(final_df['text'].iloc[0])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a9496-8f65-4b5b-acc2-9b9f877b4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for varied inputs\n",
    "input_templates = [\n",
    "    \"My gender is {gender}, I own a car: {car}, I own a house: {house}, I make {income} annually, I am {job_status}, I have {education}, I am {marital_status}, I live in {housing}, I am {age} years old, I have {children} children.\",\n",
    "    \"I am a {gender} earning {income} per year. I am {marital_status}, living in a {housing}, and I am {age} years old. I have {children} children and {education}. My job status is {job_status}.\",\n",
    "    \"{gender}, owns a car: {car}, owns a house: {house}, earning {income}, {job_status}, {education}, {marital_status}, living in {housing}, {age} years old, {children} children.\",\n",
    "    \"I earn {income} yearly and am {marital_status}. I live in a {housing}, I am {age} years old, and I have {children} children.\",\n",
    "    \"My details: {gender}, Car Ownership: {car}, Property Ownership: {house}, Annual Income: {income}, Education: {education}, Marital Status: {marital_status}, Housing Type: {housing}, Age: {age}, Children: {children}.\",\n",
    "    \"I am a {gender} who owns a car ({car}) and a house ({house}). I earn {income} per year and am {marital_status}. My education level is {education}, and I live in a {housing}. I am {age} years old and have {children} children. My job is {job_status}.\",\n",
    "    \"I am {age} years old and make {income} annually. I am {marital_status}, living in a {housing}. I own a car: {car}. I own a house: {house}. I have {children} children and {education}.\",\n",
    "    \"I earn {income} yearly and have {children} children. I am a {gender} who owns a car ({car}) and a house ({house}). I am {marital_status} and live in a {housing}. My education level is {education}, and I am {age} years old.\",\n",
    "    \"I have {education} and make {income} yearly. I am {age} years old and {job_status}. I own a car ({car}) and a house ({house}). I am {marital_status} and live in a {housing}. I have {children} children.\",\n",
    "    \"{gender} with an annual income of {income}, {job_status}, living in a {housing}. {marital_status}, with {education}. I own a car ({car}) and a house ({house}). Age: {age}, Children: {children}.\",\n",
    "    \"I make {income} per year and live in a {housing}. I am {marital_status} with {education}, {age} years old, and have {children} children. Car ownership: {car}, Property ownership: {house}.\",\n",
    "    \"I am {age} years old, {marital_status}, and earn {income} per year. I live in a {housing} and have {children} children. Car: {car}, House: {house}, Education: {education}.\",\n",
    "    \"I am a {gender} who earns {income} annually. I have {children} children and am {age} years old. I live in a {housing} and own a car ({car}) and a house ({house}).\",\n",
    "    \"{gender}, {age} years old, earns {income}, lives in a {housing}, is {marital_status}, owns a car: {car}, owns a house: {house}, has {education}, and {children} children.\",\n",
    "    \"{gender}, owns a car: {car}, owns a house: {house}, earns {income}, is {age} years old, {education}, {marital_status}, {housing}, {children} children.\"\n",
    "]\n",
    "\n",
    "# Generate varied natural-language inputs\n",
    "def generate_varied_inputs(row):\n",
    "    # Choose a random template\n",
    "    template = random.choice(input_templates)\n",
    "    \n",
    "    # Fill placeholders with actual values or defaults\n",
    "    filled_input = template.format(\n",
    "        gender=\"Male\" if row['Gender'] == 'M' else \"Female\",\n",
    "        car=\"yes\" if row['Car Ownership'] == 'Y' else \"no\",\n",
    "        house=\"yes\" if row['Property Ownership'] == 'Y' else \"no\",\n",
    "        income=f\"{row['Annual Income']:.2f}\" if pd.notna(row['Annual Income']) else \"unknown income\",\n",
    "        job_status=\"working\" if row['Income Category'] == \"Working\" else \"not working\" if pd.notna(row['Income Category']) else \"unknown job status\",\n",
    "        education=row['Education Level'] if pd.notna(row['Education Level']) else \"unknown education level\",\n",
    "        marital_status=row['Marital Status'] if pd.notna(row['Marital Status']) else \"unknown marital status\",\n",
    "        housing=row['Housing Type'] if pd.notna(row['Housing Type']) else \"unknown housing type\",\n",
    "        age=f\"{(row['Age (Years)'])}\" if pd.notna(row['Age (Years)']) else \"unknown age\",\n",
    "        children=f\"{int(row['Number of Children'])}\" if pd.notna(row['Number of Children']) else \"unknown number of\"\n",
    "    )\n",
    "    return filled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d87e11-b864-4256-aa52-9a005a448b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = df.copy()\n",
    "# Apply the varied input generation to each row\n",
    "random_df[\"text\"] = random_df.apply(generate_varied_inputs, axis=1)\n",
    "\n",
    "# Keep the label (reason) structured and tagged\n",
    "random_df[\"label\"] = random_df[\"Reason\"].apply(lambda reason: f\"<label> {reason} </label>\")\n",
    "\n",
    "# Resulting dataframe with varied inputs and structured labels\n",
    "random_df = random_df[[\"text\", \"label\"]]\n",
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a97b2a-5ea0-4c90-b4ba-0c05e83f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.1-8B\"\n",
    "new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.2-8b-CC/\"\n",
    "\n",
    "instruct_base_model = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "instruct_new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.2-8b-Instruct-CC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765187fa-57b1-4600-90ae-78bb4a442e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a905ad7-0c94-474c-8bf0-fd0ce3947412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to HuggingFace datasets\n",
    "final_dataset = Dataset.from_pandas(final_df)\n",
    "random_dataset = Dataset.from_pandas(random_df)\n",
    "\n",
    "# Split datasets into train and eval\n",
    "final_split = final_dataset.train_test_split(test_size=0.2)\n",
    "random_split = random_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "final_train_dataset = final_split['train']\n",
    "final_eval_dataset = final_split['test']\n",
    "\n",
    "random_train_dataset = random_split['train']\n",
    "random_eval_dataset = random_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d699e7-f389-4b8b-896d-82f8cfe0d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback to save model every 5 epochs\n",
    "class SaveEveryNEpochsCallback(TrainerCallback):\n",
    "    def __init__(self, save_every_n_epochs, output_dir):\n",
    "        self.save_every_n_epochs = save_every_n_epochs\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.epoch % self.save_every_n_epochs == 0:\n",
    "            model_save_path = os.path.join(self.output_dir, f\"checkpoint-{int(state.epoch)}-epochs\")\n",
    "            kwargs[\"model\"].save_pretrained(model_save_path)\n",
    "            kwargs[\"tokenizer\"].save_pretrained(model_save_path)\n",
    "            print(f\"Model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96b129-e14d-42e0-9966-7b7661b699a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3 on CC Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da285a-bb2a-4593-8bf6-5c590e32d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_arguments(output_dir, num_epochs):\n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        gradient_accumulation_steps=16,  # Larger effective batch size\n",
    "        optim=\"adamw_bnb_8bit\",  # Optimized optimizer\n",
    "        num_train_epochs=num_epochs,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,  # Less frequent evaluation\n",
    "        logging_steps=100,  # Align with eval_steps\n",
    "        warmup_steps=10,\n",
    "        logging_strategy=\"steps\",\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,  # Mixed precision\n",
    "        dataloader_num_workers=8,  # Speed up data loading\n",
    "        group_by_length=True,\n",
    "        load_best_model_at_end=True,  # Ensure this is set\n",
    "        report_to=\"wandb\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5d0ce-9f75-4e33-9830-085333cce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_and_save_model(model, tokenizer, train_dataset, eval_dataset, peft_config, new_model_path, output_suffix, num_epochs=100, save_every_n_epochs=5):\n",
    "    # Save first epoch model for debugging\n",
    "    print(f\"Training for 1 epoch to save a debug model...\")\n",
    "    debug_training_args = get_training_arguments(new_model_path + output_suffix + \"-1-epoch\", num_epochs=1)\n",
    "\n",
    "    debug_trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=512,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        args=debug_training_args,\n",
    "        packing=False,\n",
    "    )\n",
    "\n",
    "    # Train for one epoch and save\n",
    "    debug_trainer.train()\n",
    "    model.save_pretrained(new_model_path + output_suffix + \"-1-epoch\")\n",
    "    tokenizer.save_pretrained(new_model_path + output_suffix + \"-1-epoch\")\n",
    "    print(f\"Debug model saved after 1 epoch at {new_model_path + output_suffix + '-1-epoch'}\")\n",
    "\n",
    "    # Continue training for the full epochs\n",
    "    print(f\"Continuing training for {num_epochs} epochs...\")\n",
    "    full_training_args = get_training_arguments(new_model_path + output_suffix, num_epochs)\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=512,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        args=full_training_args,\n",
    "        packing=False,\n",
    "    )\n",
    "\n",
    "    # Add early stopping and periodic saving callbacks\n",
    "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=5))\n",
    "    trainer.add_callback(SaveEveryNEpochsCallback(save_every_n_epochs=save_every_n_epochs, output_dir=new_model_path + output_suffix))\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save_pretrained(new_model_path + output_suffix + \"-final\")\n",
    "    tokenizer.save_pretrained(new_model_path + output_suffix + \"-final\")\n",
    "    print(f\"Final model saved at {new_model_path + output_suffix + '-final'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f8dc56-298e-4c56-9c78-a7b4d8ab8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628662d7-9884-4cd1-91a6-b98ee2ed8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Modify load_model_and_tokenizer function\n",
    "def load_model_and_tokenizer(base_model_path, attn_implementation=\"default\"):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=attn_implementation\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "    model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "    return model, tokenizer\n",
    "    \n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "# modules = find_all_linear_names(model)\n",
    "# print(modules)\n",
    "# Define LoRA config once since both models use it\n",
    "def create_lora_config(model):\n",
    "    modules = find_all_linear_names(model)\n",
    "    return LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=modules\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b8cee-084a-4510-96b0-ab5c64d57da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Base Model and Tokenizer\n",
    "print(\"Loading Base Model...\")\n",
    "base_model, base_tokenizer = load_model_and_tokenizer(\n",
    "    base_model_path=base_model, \n",
    "    attn_implementation=attn_implementation\n",
    ")\n",
    "# Define LoRA Config\n",
    "print(\"Creating LoRA Configuration...\")\n",
    "peft_config = create_lora_config(base_model) \n",
    "\n",
    "# Apply PEFT to the model\n",
    "base_model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "# Train Base Model on Final Dataset\n",
    "print(\"Training Base Model on Final Dataset...\")\n",
    "train_and_save_model(\n",
    "    model=base_model,\n",
    "    new_model_path=new_model,\n",
    "    tokenizer=base_tokenizer,\n",
    "    train_dataset=final_train_dataset,\n",
    "    eval_dataset=final_eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    output_suffix=\"base\",\n",
    "    num_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24a096-958e-4a0f-bc87-6d3d14d0434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Instruct Model\n",
    "print(\"Loading Instruct Model...\")\n",
    "instruct_model, instruct_tokenizer = load_model_and_tokenizer(\n",
    "    base_model_path=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    attn_implementation=attn_implementation\n",
    "\n",
    ")\n",
    "peft_config = create_lora_config(instruct_model)\n",
    "\n",
    "# Apply PEFT to the model\n",
    "instruct_model = get_peft_model(instruct_model, peft_config)\n",
    "\n",
    "# Train Base Model on Final Dataset\n",
    "print(\"Training Base Model on Final Dataset...\")\n",
    "train_and_save_model(\n",
    "    model=instruct_model,\n",
    "    new_model_path=instruct_new_model,\n",
    "    tokenizer=instruct_tokenizer,\n",
    "    train_dataset=random_train_dataset,\n",
    "    eval_dataset=random_eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    output_suffix=\"instruct\",\n",
    "    num_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03e05e-8238-415e-9ae7-3891c0eabd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bbfc4-9fa3-4eed-9c7d-c49bf67da5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Define paths\n",
    "base_model = \"meta-llama/Llama-3.1-8B\"\n",
    "new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.2-8b-CC/\"\n",
    "instruct_base_model = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "instruct_new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.2-8b-Instruct-CC/\"\n",
    "\n",
    "# Define test prompts\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a highly knowledgeable financial advisor specializing in credit card approvals.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Why was my application rejected? My age is 30, income is $40,000, and credit score is 580.\"}\n",
    "]\n",
    "\n",
    "# Helper function for testing models\n",
    "def test_model(model_path, tokenizer_path, messages):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\")\n",
    "    \n",
    "    # Manually construct prompt\n",
    "    prompt = \"\"\n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"system\":\n",
    "            prompt += f\"System: {msg['content']}\\n\"\n",
    "        elif msg[\"role\"] == \"user\":\n",
    "            prompt += f\"User: {msg['content']}\\n\"\n",
    "    prompt += \"Assistant:\"  # Add assistant prompt for model response\n",
    "\n",
    "    # Tokenize and generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id  # Use correct padding token\n",
    "    )\n",
    "\n",
    "    # Decode response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response_split = response.split(\"Assistant: \")\n",
    "    if len(response_split) > 1:\n",
    "        response_content = response_split[1]\n",
    "    else:\n",
    "        response_content = response  # Fallback to entire response\n",
    "    return response_content\n",
    "    \n",
    "# Test the models\n",
    "print(\"Testing base model...\")\n",
    "base_response = test_model(new_model + \"base-final\", new_model + \"base-final\", messages)\n",
    "print(\"Base Model Response:\")\n",
    "print(base_response)\n",
    "\n",
    "print(\"Testing instruct model...\")\n",
    "instruct_response = test_model(instruct_new_model + \"instruct-final\", instruct_new_model + \"instruct-final\", messages)\n",
    "print(\"Instruct Model Response:\")\n",
    "print(instruct_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfd4b8-02e8-4e74-8613-59934f551218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
