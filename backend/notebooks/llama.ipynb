{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666d56dd-a534-4907-8c32-e3d94ab3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import re\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import bitsandbytes as bnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae67b3f7-d781-4d5c-a92c-dbf4bbdf463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface-cli login --token key   \n",
    "# wandb login --relogin key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c44e03d-c5a3-4d95-9fe1-b32659ffeeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded and merged successfully.\n",
      "Approval status merged successfully.\n",
      "Preprocessing completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type  Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment          32                      4542.0           1.0   \n",
       "1   Rented apartment          32                      4542.0           1.0   \n",
       "2  House / apartment          58                      1134.0           1.0   \n",
       "3  House / apartment          52                      3051.0           1.0   \n",
       "4  House / apartment          52                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \n",
       "0         1.0    0.0    0.0             NaN          2.0         1  \n",
       "1         1.0    0.0    0.0             NaN          2.0         1  \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1  \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1  \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#https://www.kaggle.com/datasets/rikdifos/credit-card-approval-prediction\n",
    "# Load the application_record dataset\n",
    "data = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/application_record.csv\")\n",
    "# Load the credit_record dataset\n",
    "record = pd.read_csv(\"/opt/notebooks/Chatbot-Credit-Card/backend/dataset/credit-card-approval/credit_record.csv\")\n",
    "# Find the first account open month for each user\n",
    "begin_month = record.loc[record.groupby(\"ID\")[\"MONTHS_BALANCE\"].idxmin()]\n",
    "begin_month = begin_month.rename(columns={\"MONTHS_BALANCE\": \"begin_month\"})\n",
    "\n",
    "# Merge the datasets\n",
    "df = pd.merge(data, begin_month, how=\"left\", on=\"ID\")\n",
    "print(\"Datasets loaded and merged successfully.\")\n",
    "# Define approval logic based on multiple criteria\n",
    "def determine_approval(row):\n",
    "    # Define custom approval logic\n",
    "    if row[\"STATUS\"] in [\"0\", \"1\", \"C\", \"X\"]:  # Good credit status\n",
    "            return 1  # Approved\n",
    "    return 0  # Default to denial if STATUS is bad or missing\n",
    "\n",
    "# Apply logic to determine approval (filling missing STATUS values first)\n",
    "record[\"STATUS\"] = record[\"STATUS\"].fillna(\"X\")  # Handle missing values\n",
    "record[\"Approved\"] = record.apply(determine_approval, axis=1)\n",
    "# Aggregate approval status for each ID (disapproval if any ID has disqualifying criteria)\n",
    "approval_status = record.groupby(\"ID\")[\"Approved\"].min().reset_index()\n",
    "# Merge approval status back into the main dataset, avoiding \"_x\" and \"_y\" columns\n",
    "df = pd.merge(data, approval_status, how=\"left\", on=\"ID\")\n",
    "df[\"Approved\"] = df[\"Approved\"].fillna(0).astype(int)  # Fill missing approvals as denial\n",
    "print(\"Approval status merged successfully.\")\n",
    "# Preprocess the 'DAYS_BIRTH' column to convert days to years\n",
    "df['DAYS_BIRTH'] = (-df['DAYS_BIRTH'] // 365).fillna(0).astype(int)\n",
    "df.drop(columns=['ID'], inplace=True)\n",
    "# Preprocess the 'DAYS_EMPLOYED' column to get absolute values and handle unemployment\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "# Handle missing or infinite values in numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].replace([np.inf, -np.inf], np.nan)  # Replace infinities with NaN\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())  # Fill NaN with median values\n",
    "print(\"Preprocessing completed successfully.\")\n",
    "\n",
    "# Define the feature mapping dictionary\n",
    "feature_mapping = {\n",
    "    'CODE_GENDER': 'Gender',\n",
    "    'FLAG_OWN_CAR': 'Car Ownership',\n",
    "    'FLAG_OWN_REALTY': 'Property Ownership',\n",
    "    'CNT_CHILDREN': 'Number of Children',\n",
    "    'AMT_INCOME_TOTAL': 'Annual Income',\n",
    "    'NAME_INCOME_TYPE': 'Income Category',\n",
    "    'NAME_EDUCATION_TYPE': 'Education Level',\n",
    "    'NAME_FAMILY_STATUS': 'Marital Status',\n",
    "    'NAME_HOUSING_TYPE': 'Housing Type',\n",
    "    'DAYS_BIRTH': 'Age (Days)',\n",
    "    'DAYS_EMPLOYED': 'Employment Duration (Days)',\n",
    "    'FLAG_MOBIL': 'Mobile Phone',\n",
    "    'FLAG_WORK_PHONE': 'Work Phone',\n",
    "    'FLAG_PHONE': 'Phone',\n",
    "    'FLAG_EMAIL': 'Email',\n",
    "    'OCCUPATION_TYPE': 'Occupation',\n",
    "    'CNT_FAM_MEMBERS': 'Family Size',\n",
    "    'STATUS': 'Credit Status'\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame using the mapping\n",
    "df.rename(columns=feature_mapping, inplace=True)\n",
    "\n",
    "# Display the first few rows to confirm the changes\n",
    "df.head()\n",
    "df.rename(columns={'TARGET': 'Approved'}, inplace=True)\n",
    "# Display the first few rows to confirm the change\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c9fc4d-7637-4dc9-b335-5733a304c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to -0.77, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Email, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denied</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was denied due to -1.62, Emai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction    Actual                                        Explanation\n",
       "0   Approved  Approved  This application was approved due to Employmen...\n",
       "1   Approved  Approved  This application was approved due to Employmen...\n",
       "2   Approved  Approved  This application was approved due to -0.77, Ma...\n",
       "3   Approved  Approved  This application was approved due to Email, -0...\n",
       "4     Denied  Approved  This application was denied due to -1.62, Emai..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation_df = pd.read_csv('/opt/notebooks/Chatbot-Credit-Card/backend/dataset/explanations_df.csv')\n",
    "# explanation_df.drop(['Approved','Explanation'], axis=1, inplace=True)\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2540947f-ff72-40c0-8d27-7f310edb9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, -0.77, Marital Status, Work Phone, -0.15, Number of Children, -0.81, Family Size, Annual Income.\n"
     ]
    }
   ],
   "source": [
    "print(explanation_df['Explanation'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55a4c06-ecdb-437b-9a1f-d89d653d9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove numbers and clean the Explanation column\n",
    "def clean_explanation(text):\n",
    "    return re.sub(r'[-+]?\\d*\\.\\d+|\\d+', '', text).replace(', ,', ',').replace(' ,', ',').strip(\", \")\n",
    "\n",
    "# Apply the cleaning function to the Explanation column\n",
    "explanation_df[\"Explanation\"] = explanation_df[\"Explanation\"].apply(clean_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3809e3a1-e7af-4f16-964f-39ceee20d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, Marital Status, Work Phone, Number of Children, Family Size, Annual Income.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to, Marital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Approved</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was approved due to Email, Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denied</td>\n",
       "      <td>Approved</td>\n",
       "      <td>This application was denied due to, Email, Hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction    Actual                                        Explanation\n",
       "0   Approved  Approved  This application was approved due to Employmen...\n",
       "1   Approved  Approved  This application was approved due to Employmen...\n",
       "2   Approved  Approved  This application was approved due to, Marital ...\n",
       "3   Approved  Approved  This application was approved due to Email, Nu...\n",
       "4     Denied  Approved  This application was denied due to, Email, Hou..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame with the cleaned Explanation column\n",
    "print(explanation_df['Explanation'].iloc[0])\n",
    "explanation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f1cb95-f0a3-44d5-8df2-64849a0c0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={'Age (Days)': 'Age (Years)'}, inplace=True)\n",
    "df.rename(columns={'Employment Duration' : 'Employment Duration (Days)'}, inplace=True)\n",
    "df['Age (Days)'] = df['Age (Days)'].astype(str) + \" years old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56ecd81d-edae-4d65-be32-13503fe03ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Days), Housing Type, Marital Status, Work Phone, Number of Children, Family Size, Annual Income.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to, Marital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email, Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to, Email, Hou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type    Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                      4542.0           1.0   \n",
       "1   Rented apartment  32 years old                      4542.0           1.0   \n",
       "2  House / apartment  58 years old                      1134.0           1.0   \n",
       "3  House / apartment  52 years old                      3051.0           1.0   \n",
       "4  House / apartment  52 years old                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to, Marital ...  \n",
       "3  This application was approved due to Email, Nu...  \n",
       "4  This application was denied due to, Email, Hou...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine explanation_df and df based on index\n",
    "df['Reason'] = explanation_df['Explanation'].reset_index(drop=True)\n",
    "\n",
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa91600a-5b74-4c15-a021-811231791deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically replace labels with row values\n",
    "def insert_numbers_dynamically(row):\n",
    "    reason = row['Reason']\n",
    "    \n",
    "    # Extract all parts of the reason where dynamic replacement is needed\n",
    "    labels = re.findall(r'([A-Za-z\\s()]+)', reason)\n",
    "    \n",
    "    for label in labels:\n",
    "        # Match the label to the corresponding column name\n",
    "        column_name = None\n",
    "        for col in df.columns:\n",
    "            # Normalize column names and labels for matching\n",
    "            normalized_col = re.sub(r'[\\s()]+', '', col).lower()\n",
    "            normalized_label = re.sub(r'[\\s()]+', '', label).lower()\n",
    "            \n",
    "            if normalized_col == normalized_label:\n",
    "                column_name = col\n",
    "                break\n",
    "        \n",
    "        if column_name and column_name in row:  # Ensure column exists in the DataFrame\n",
    "            # Replace the label with the corresponding value from the row\n",
    "            value = row[column_name]\n",
    "            # Ensure proper replacement in the text\n",
    "            reason = reason.replace(label, f\"{label.strip()} {value}\")\n",
    "    \n",
    "    return reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5de84f6b-5383-4ddf-97bf-34a9e40bb3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Days)</th>\n",
       "      <th>Employment Duration (Days)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to,Marital S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email,Num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to,Email 1.0,H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type    Age (Days)  Employment Duration (Days)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                      4542.0           1.0   \n",
       "1   Rented apartment  32 years old                      4542.0           1.0   \n",
       "2  House / apartment  58 years old                      1134.0           1.0   \n",
       "3  House / apartment  52 years old                      3051.0           1.0   \n",
       "4  House / apartment  52 years old                      3051.0           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to,Marital S...  \n",
       "3  This application was approved due to Email,Num...  \n",
       "4  This application was denied due to,Email 1.0,H...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each row in the DataFrame\n",
    "df['Reason'] = df.apply(insert_numbers_dynamically, axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e326c282-2355-4055-ab40-42b98f101d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Car Ownership</th>\n",
       "      <th>Property Ownership</th>\n",
       "      <th>Number of Children</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Income Category</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Housing Type</th>\n",
       "      <th>Age (Years)</th>\n",
       "      <th>Employment Duration (Years)</th>\n",
       "      <th>Mobile Phone</th>\n",
       "      <th>Work Phone</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Email</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Family Size</th>\n",
       "      <th>Approved</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>12.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>427500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>32 years old</td>\n",
       "      <td>12.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Employmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>58 years old</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to,Marital S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was approved due to Email,Num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>52 years old</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This application was denied due to,Email 1.0,H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Car Ownership Property Ownership  Number of Children  Annual Income  \\\n",
       "0      M             Y                  Y                   0       427500.0   \n",
       "1      M             Y                  Y                   0       427500.0   \n",
       "2      M             Y                  Y                   0       112500.0   \n",
       "3      F             N                  Y                   0       270000.0   \n",
       "4      F             N                  Y                   0       270000.0   \n",
       "\n",
       "        Income Category                Education Level        Marital Status  \\\n",
       "0               Working               Higher education        Civil marriage   \n",
       "1               Working               Higher education        Civil marriage   \n",
       "2               Working  Secondary / secondary special               Married   \n",
       "3  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "4  Commercial associate  Secondary / secondary special  Single / not married   \n",
       "\n",
       "        Housing Type   Age (Years)  Employment Duration (Years)  Mobile Phone  \\\n",
       "0   Rented apartment  32 years old                        12.44           1.0   \n",
       "1   Rented apartment  32 years old                        12.44           1.0   \n",
       "2  House / apartment  58 years old                         3.11           1.0   \n",
       "3  House / apartment  52 years old                         8.36           1.0   \n",
       "4  House / apartment  52 years old                         8.36           1.0   \n",
       "\n",
       "   Work Phone  Phone  Email      Occupation  Family Size  Approved  \\\n",
       "0         1.0    0.0    0.0             NaN          2.0         1   \n",
       "1         1.0    0.0    0.0             NaN          2.0         1   \n",
       "2         0.0    0.0    0.0  Security staff          2.0         1   \n",
       "3         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "4         0.0    1.0    1.0     Sales staff          1.0         1   \n",
       "\n",
       "                                              Reason  \n",
       "0  This application was approved due to Employmen...  \n",
       "1  This application was approved due to Employmen...  \n",
       "2  This application was approved due to,Marital S...  \n",
       "3  This application was approved due to Email,Num...  \n",
       "4  This application was denied due to,Email 1.0,H...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert \"Employment Duration (Days)\" to years in-place\n",
    "df[\"Employment Duration (Days)\"] = df[\"Employment Duration (Days)\"].apply(lambda x: round(x / 365.0, 2) if not pd.isna(x) else np.nan)\n",
    "df.rename(columns={\"Age (Days)\": \"Age (Years)\", \"Employment Duration (Days)\": \"Employment Duration (Years)\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e94d63b-b049-48ba-84c1-d4d546924bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Update the \"Reason\" column to match the new labels\n",
    "def update_reason(reason_text):\n",
    "    reason_text = reason_text.replace(\"Age (Days)\", \"Age (Years)\")\n",
    "    reason_text = reason_text.replace(\"Employment Duration (Days)\", \"Employment Duration (Years)\")\n",
    "    return reason_text\n",
    "\n",
    "df[\"Reason\"] = df[\"Reason\"].apply(update_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569a1958-db10-4301-bc49-20782c1b67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application was approved due to Employment Duration (Years),Housing Type Rented apartment,Marital Status Civil marriage,Work Phone 1.0,Number of Children 0,Family Size 2.0,Annual Income 427500.0.\n"
     ]
    }
   ],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(df['Reason'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682e67b6-5fbb-4f4b-ab3c-d41b8f5a274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagged_input_and_label(row):\n",
    "    # Generate the reasoning part of the label using the same tags as input\n",
    "    reasoning_parts = [\n",
    "        f\"<gender> {'Male' if row['Gender'] == 'M' else 'Female'} </gender>\" if pd.notna(row.get('Gender')) else None,\n",
    "        f\"<age> {row['Age (Years)']} years old </age>\" if pd.notna(row.get('Age (Years)')) else None,\n",
    "        f\"<car_ownership> {'yes' if row['Car Ownership'] == 'Y' else 'no'} </car_ownership>\" if pd.notna(row.get('Car Ownership')) else None,\n",
    "        f\"<property_ownership> {'yes' if row['Property Ownership'] == 'Y' else 'no'} </property_ownership>\" if pd.notna(row.get('Property Ownership')) else None,\n",
    "        f\"<number_of_children> {int(row['Number of Children'])} </number_of_children>\" if pd.notna(row.get('Number of Children')) else None,\n",
    "        f\"<annual_income> {row['Annual Income']} </annual_income>\" if pd.notna(row.get('Annual Income')) else None,\n",
    "        f\"<income_category> {row['Income Category']} </income_category>\" if pd.notna(row.get('Income Category')) else None,\n",
    "        f\"<education_level> {row['Education Level']} </education_level>\" if pd.notna(row.get('Education Level')) else None,\n",
    "        f\"<marital_status> {row['Marital Status']} </marital_status>\" if pd.notna(row.get('Marital Status')) else None,\n",
    "        f\"<housing_type> {row['Housing Type']} </housing_type>\" if pd.notna(row.get('Housing Type')) else None,\n",
    "        f\"<employment_duration> {row['Employment Duration (Years)']} years </employment_duration>\" if pd.notna(row.get('Employment Duration (Years)')) else None,\n",
    "        f\"<mobile_phone> {'yes' if row['Mobile Phone'] == 1 else 'no'} </mobile_phone>\" if pd.notna(row.get('Mobile Phone')) else None,\n",
    "        f\"<work_phone> {'yes' if row['Work Phone'] == 1 else 'no'} </work_phone>\" if pd.notna(row.get('Work Phone')) else None,\n",
    "        f\"<email> {'yes' if row['Email'] == 1 else 'no'} </email>\" if pd.notna(row.get('Email')) else None,\n",
    "        f\"<family_size> {row['Family Size']} </family_size>\" if pd.notna(row.get('Family Size')) else None,\n",
    "    ]\n",
    "    reasoning_text = \" \".join([part for part in reasoning_parts if part is not None])\n",
    "    label = f\"<approval_status> Approved </approval_status> <reasoning> {reasoning_text} </reasoning>\"\n",
    "\n",
    "    # Generate input in the same way\n",
    "    input_parts = reasoning_parts  # Reuse the reasoning parts for consistency\n",
    "    input_text = \" \".join([part for part in input_parts if part is not None])\n",
    "    input_section = f\"{input_text}\"\n",
    "\n",
    "    return input_section, label\n",
    "\n",
    "def generate_plain_input_and_label(row):\n",
    "    # Generate the reasoning part of the label\n",
    "    reasoning_parts = [\n",
    "        f\"Gender: {'Male' if row['Gender'] == 'M' else 'Female'}\" if pd.notna(row.get('Gender')) else None,\n",
    "        f\"Age: {row['Age (Years)']} years old\" if pd.notna(row.get('Age (Years)')) else None,\n",
    "        f\"Car Ownership: {'Yes' if row['Car Ownership'] == 'Y' else 'No'}\" if pd.notna(row.get('Car Ownership')) else None,\n",
    "        f\"Property Ownership: {'Yes' if row['Property Ownership'] == 'Y' else 'No'}\" if pd.notna(row.get('Property Ownership')) else None,\n",
    "        f\"Number of Children: {int(row['Number of Children'])}\" if pd.notna(row.get('Number of Children')) else None,\n",
    "        f\"Annual Income: {row['Annual Income']}\" if pd.notna(row.get('Annual Income')) else None,\n",
    "        f\"Income Category: {row['Income Category']}\" if pd.notna(row.get('Income Category')) else None,\n",
    "        f\"Education Level: {row['Education Level']}\" if pd.notna(row.get('Education Level')) else None,\n",
    "        f\"Marital Status: {row['Marital Status']}\" if pd.notna(row.get('Marital Status')) else None,\n",
    "        f\"Housing Type: {row['Housing Type']}\" if pd.notna(row.get('Housing Type')) else None,\n",
    "        f\"Employment Duration: {row['Employment Duration (Years)']} years\" if pd.notna(row.get('Employment Duration (Years)')) else None,\n",
    "        f\"Mobile Phone: {'Yes' if row['Mobile Phone'] == 1 else 'No'}\" if pd.notna(row.get('Mobile Phone')) else None,\n",
    "        f\"Work Phone: {'Yes' if row['Work Phone'] == 1 else 'No'}\" if pd.notna(row.get('Work Phone')) else None,\n",
    "        f\"Email: {'Yes' if row['Email'] == 1 else 'No'}\" if pd.notna(row.get('Email')) else None,\n",
    "        f\"Family Size: {row['Family Size']}\" if pd.notna(row.get('Family Size')) else None,\n",
    "    ]\n",
    "    reasoning_text = \". \".join([part for part in reasoning_parts if part is not None])\n",
    "    label = f\"Approval Status: Approved. Reasoning: {reasoning_text}.\"\n",
    "\n",
    "    # Generate input in the same way\n",
    "    input_text = reasoning_text  # Reuse the reasoning parts for consistency\n",
    "\n",
    "    return input_text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4239c25-2bfb-43f6-a7c5-01b023d7acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row\n",
    "df[\"text\"], df[\"label\"] = zip(*df.apply(generate_tagged_input_and_label, axis=1))\n",
    "\n",
    "# Keep only the required columns\n",
    "final_df = df[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98c88087-3265-4990-9b80-2efbd8b1432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "\n",
      "<approval_status> Approved </approval_status> <reasoning> <gender> Male </gender> <age> 32 years old years old </age> <car_ownership> yes </car_ownership> <property_ownership> yes </property_ownership> <number_of_children> 0 </number_of_children> <annual_income> 427500.0 </annual_income> <income_category> Working </income_category> <education_level> Higher education </education_level> <marital_status> Civil marriage </marital_status> <housing_type> Rented apartment </housing_type> <employment_duration> 12.44 years </employment_duration> <mobile_phone> yes </mobile_phone> <work_phone> yes </work_phone> <email> no </email> <family_size> 2.0 </family_size> </reasoning>\n",
      "Input\n",
      "\n",
      "<gender> Male </gender> <age> 32 years old years old </age> <car_ownership> yes </car_ownership> <property_ownership> yes </property_ownership> <number_of_children> 0 </number_of_children> <annual_income> 427500.0 </annual_income> <income_category> Working </income_category> <education_level> Higher education </education_level> <marital_status> Civil marriage </marital_status> <housing_type> Rented apartment </housing_type> <employment_duration> 12.44 years </employment_duration> <mobile_phone> yes </mobile_phone> <work_phone> yes </work_phone> <email> no </email> <family_size> 2.0 </family_size>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;gender&gt; Male &lt;/gender&gt; &lt;age&gt; 32 years old yea...</td>\n",
       "      <td>&lt;approval_status&gt; Approved &lt;/approval_status&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;gender&gt; Male &lt;/gender&gt; &lt;age&gt; 32 years old yea...</td>\n",
       "      <td>&lt;approval_status&gt; Approved &lt;/approval_status&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;gender&gt; Male &lt;/gender&gt; &lt;age&gt; 58 years old yea...</td>\n",
       "      <td>&lt;approval_status&gt; Approved &lt;/approval_status&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;gender&gt; Female &lt;/gender&gt; &lt;age&gt; 52 years old y...</td>\n",
       "      <td>&lt;approval_status&gt; Approved &lt;/approval_status&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;gender&gt; Female &lt;/gender&gt; &lt;age&gt; 52 years old y...</td>\n",
       "      <td>&lt;approval_status&gt; Approved &lt;/approval_status&gt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  <gender> Male </gender> <age> 32 years old yea...   \n",
       "1  <gender> Male </gender> <age> 32 years old yea...   \n",
       "2  <gender> Male </gender> <age> 58 years old yea...   \n",
       "3  <gender> Female </gender> <age> 52 years old y...   \n",
       "4  <gender> Female </gender> <age> 52 years old y...   \n",
       "\n",
       "                                               label  \n",
       "0  <approval_status> Approved </approval_status> ...  \n",
       "1  <approval_status> Approved </approval_status> ...  \n",
       "2  <approval_status> Approved </approval_status> ...  \n",
       "3  <approval_status> Approved </approval_status> ...  \n",
       "4  <approval_status> Approved </approval_status> ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first value in the 'Reason' column\n",
    "print(\"Label\\n\")\n",
    "print(final_df['label'].iloc[0])\n",
    "print(\"Input\\n\")\n",
    "print(final_df['text'].iloc[0])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b3a9496-8f65-4b5b-acc2-9b9f877b4e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for varied inputs\n",
    "input_templates = [\n",
    "    \"My gender is {gender}, I own a car: {car}, I own a house: {house}, I make {income} annually, I am {job_status}, I have {education}, I am {marital_status}, I live in {housing}, I am {age} years old, I have {children} children.\",\n",
    "    \"I am a {gender} earning {income} per year. I am {marital_status}, living in a {housing}, and I am {age} years old. I have {children} children and {education}. My job status is {job_status}.\",\n",
    "    \"{gender}, owns a car: {car}, owns a house: {house}, earning {income}, {job_status}, {education}, {marital_status}, living in {housing}, {age} years old, {children} children.\",\n",
    "    \"I earn {income} yearly and am {marital_status}. I live in a {housing}, I am {age} years old, and I have {children} children.\",\n",
    "    \"My details: {gender}, Car Ownership: {car}, Property Ownership: {house}, Annual Income: {income}, Education: {education}, Marital Status: {marital_status}, Housing Type: {housing}, Age: {age}, Children: {children}.\",\n",
    "    \"I am a {gender} who owns a car ({car}) and a house ({house}). I earn {income} per year and am {marital_status}. My education level is {education}, and I live in a {housing}. I am {age} years old and have {children} children. My job is {job_status}.\",\n",
    "    \"I am {age} years old and make {income} annually. I am {marital_status}, living in a {housing}. I own a car: {car}. I own a house: {house}. I have {children} children and {education}.\",\n",
    "    \"I earn {income} yearly and have {children} children. I am a {gender} who owns a car ({car}) and a house ({house}). I am {marital_status} and live in a {housing}. My education level is {education}, and I am {age} years old.\",\n",
    "    \"I have {education} and make {income} yearly. I am {age} years old and {job_status}. I own a car ({car}) and a house ({house}). I am {marital_status} and live in a {housing}. I have {children} children.\",\n",
    "    \"{gender} with an annual income of {income}, {job_status}, living in a {housing}. {marital_status}, with {education}. I own a car ({car}) and a house ({house}). Age: {age}, Children: {children}.\",\n",
    "    \"I make {income} per year and live in a {housing}. I am {marital_status} with {education}, {age} years old, and have {children} children. Car ownership: {car}, Property ownership: {house}.\",\n",
    "    \"I am {age} years old, {marital_status}, and earn {income} per year. I live in a {housing} and have {children} children. Car: {car}, House: {house}, Education: {education}.\",\n",
    "    \"I am a {gender} who earns {income} annually. I have {children} children and am {age} years old. I live in a {housing} and own a car ({car}) and a house ({house}).\",\n",
    "    \"{gender}, {age} years old, earns {income}, lives in a {housing}, is {marital_status}, owns a car: {car}, owns a house: {house}, has {education}, and {children} children.\",\n",
    "    \"{gender}, owns a car: {car}, owns a house: {house}, earns {income}, is {age} years old, {education}, {marital_status}, {housing}, {children} children.\"\n",
    "]\n",
    "\n",
    "# Generate varied natural-language inputs\n",
    "def generate_varied_inputs(row):\n",
    "    # Choose a random template\n",
    "    template = random.choice(input_templates)\n",
    "    \n",
    "    # Fill placeholders with actual values or defaults\n",
    "    filled_input = template.format(\n",
    "        gender=\"Male\" if row['Gender'] == 'M' else \"Female\",\n",
    "        car=\"yes\" if row['Car Ownership'] == 'Y' else \"no\",\n",
    "        house=\"yes\" if row['Property Ownership'] == 'Y' else \"no\",\n",
    "        income=f\"{row['Annual Income']:.2f}\" if pd.notna(row['Annual Income']) else \"unknown income\",\n",
    "        job_status=\"working\" if row['Income Category'] == \"Working\" else \"not working\" if pd.notna(row['Income Category']) else \"unknown job status\",\n",
    "        education=row['Education Level'] if pd.notna(row['Education Level']) else \"unknown education level\",\n",
    "        marital_status=row['Marital Status'] if pd.notna(row['Marital Status']) else \"unknown marital status\",\n",
    "        housing=row['Housing Type'] if pd.notna(row['Housing Type']) else \"unknown housing type\",\n",
    "        age=f\"{(row['Age (Years)'])}\" if pd.notna(row['Age (Years)']) else \"unknown age\",\n",
    "        children=f\"{int(row['Number of Children'])}\" if pd.notna(row['Number of Children']) else \"unknown number of\"\n",
    "    )\n",
    "    return filled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27d87e11-b864-4256-aa52-9a005a448b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I make 427500.00 per year and live in a Rented...</td>\n",
       "      <td>&lt;label&gt; This application was approved due to E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have Higher education and make 427500.00 yea...</td>\n",
       "      <td>&lt;label&gt; This application was approved due to E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male, owns a car: yes, owns a house: yes, earn...</td>\n",
       "      <td>&lt;label&gt; This application was approved due to,M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female, owns a car: no, owns a house: yes, ear...</td>\n",
       "      <td>&lt;label&gt; This application was approved due to E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am 52 years old years old, Single / not marr...</td>\n",
       "      <td>&lt;label&gt; This application was denied due to,Ema...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I make 427500.00 per year and live in a Rented...   \n",
       "1  I have Higher education and make 427500.00 yea...   \n",
       "2  Male, owns a car: yes, owns a house: yes, earn...   \n",
       "3  Female, owns a car: no, owns a house: yes, ear...   \n",
       "4  I am 52 years old years old, Single / not marr...   \n",
       "\n",
       "                                               label  \n",
       "0  <label> This application was approved due to E...  \n",
       "1  <label> This application was approved due to E...  \n",
       "2  <label> This application was approved due to,M...  \n",
       "3  <label> This application was approved due to E...  \n",
       "4  <label> This application was denied due to,Ema...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_df = df.copy()\n",
    "# Apply the varied input generation to each row\n",
    "random_df[\"text\"] = random_df.apply(generate_varied_inputs, axis=1)\n",
    "\n",
    "# Keep the label (reason) structured and tagged\n",
    "random_df[\"label\"] = random_df[\"Reason\"].apply(lambda reason: f\"<label> {reason} </label>\")\n",
    "\n",
    "# Resulting dataframe with varied inputs and structured labels\n",
    "random_df = random_df[[\"text\", \"label\"]]\n",
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41a97b2a-5ea0-4c90-b4ba-0c05e83f785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = \"meta-llama/Llama-3.1-8B\"\n",
    "new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-8b-CC/\"\n",
    "base_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-8b/\"\n",
    "\n",
    "# instruct_base_model = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "instruct_new_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-8b-Instruct-CC/\"\n",
    "instruct_base_model = \"/opt/notebooks/Chatbot-Credit-Card/backend/models/llama-3.1-8b-Instruct/\"\n",
    "\n",
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "765187fa-57b1-4600-90ae-78bb4a442e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16\n",
    "attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a905ad7-0c94-474c-8bf0-fd0ce3947412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to HuggingFace datasets\n",
    "final_dataset = Dataset.from_pandas(final_df)\n",
    "random_dataset = Dataset.from_pandas(random_df)\n",
    "\n",
    "# Split datasets into train and eval\n",
    "final_split = final_dataset.train_test_split(test_size=0.2)\n",
    "random_split = random_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "final_train_dataset = final_split['train']\n",
    "final_eval_dataset = final_split['test']\n",
    "\n",
    "random_train_dataset = random_split['train']\n",
    "random_eval_dataset = random_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d699e7-f389-4b8b-896d-82f8cfe0d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback to save model every 5 epochs\n",
    "class SaveEveryNEpochsCallback(TrainerCallback):\n",
    "    def __init__(self, save_every_n_epochs, output_dir):\n",
    "        self.save_every_n_epochs = save_every_n_epochs\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.epoch % self.save_every_n_epochs == 0:\n",
    "            model_save_path = os.path.join(self.output_dir, f\"checkpoint-{int(state.epoch)}-epochs\")\n",
    "            kwargs[\"model\"].save_pretrained(model_save_path)\n",
    "            kwargs[\"tokenizer\"].save_pretrained(model_save_path)\n",
    "            print(f\"Model saved at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a96b129-e14d-42e0-9966-7b7661b699a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdnicho26\u001b[0m (\u001b[33mdnicho26-university-of-north-carolina-at-charlotte\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/notebooks/Chatbot-Credit-Card/backend/notebooks/wandb/run-20241127_165431-ubwkkhbo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/ubwkkhbo' target=\"_blank\">deft-surf-96</a></strong> to <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/ubwkkhbo' target=\"_blank\">https://wandb.ai/dnicho26-university-of-north-carolina-at-charlotte/Fine-tune%20Llama%203%20on%20CC%20Dataset/runs/ubwkkhbo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3 on CC Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4da285a-bb2a-4593-8bf6-5c590e32d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_arguments(output_dir, num_epochs):\n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=16,  \n",
    "        optim=\"adamw_bnb_8bit\",  # Optimized optimizer\n",
    "        num_train_epochs=num_epochs,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,  # Less frequent evaluation\n",
    "        logging_steps=100,  # Align with eval_steps\n",
    "        warmup_steps=10,\n",
    "        logging_strategy=\"steps\",\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,  # Mixed precision\n",
    "        dataloader_num_workers=8,  # Speed up data loading\n",
    "        group_by_length=True,\n",
    "        load_best_model_at_end=True,  # Ensure this is set\n",
    "        report_to=\"wandb\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55bb6b51-7469-4a27-a868-cdc2deea2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_labels_and_inputs(batch, predictions, step):\n",
    "    \"\"\"\n",
    "    Log inputs, labels, and predictions to wandb.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "    preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    for input_text, label_text, pred_text in zip(inputs, labels, preds):\n",
    "        wandb.log({\n",
    "            \"input\": input_text,\n",
    "            \"label\": label_text,\n",
    "            \"prediction\": pred_text,\n",
    "            \"step\": step,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cd5d0ce-9f75-4e33-9830-085333cce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_and_save_model(model, tokenizer, train_dataset, eval_dataset, peft_config, new_model_path, output_suffix, num_epochs=epochs, save_every_n_epochs=5):\n",
    "    print(f\"Continuing training for {num_epochs} epochs...\")\n",
    "    full_training_args = get_training_arguments(new_model_path + output_suffix, num_epochs)\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=512,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        args=full_training_args,\n",
    "        packing=False,\n",
    "    )\n",
    "\n",
    "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=5))\n",
    "    trainer.add_callback(SaveEveryNEpochsCallback(save_every_n_epochs=save_every_n_epochs, output_dir=new_model_path + output_suffix))\n",
    "\n",
    "    # Custom evaluation logging\n",
    "    def evaluation_logging(trainer, eval_dataset):\n",
    "        predictions = trainer.predict(eval_dataset)\n",
    "        step = trainer.state.global_step\n",
    "        for batch in eval_dataset:  # Assuming eval_dataset is iterable\n",
    "            log_labels_and_inputs(batch, predictions, step)\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Log evaluation after training\n",
    "    evaluation_logging(trainer, eval_dataset)\n",
    "\n",
    "    # Save the final trained model\n",
    "    model.save_pretrained(new_model_path + output_suffix + \"-final\")\n",
    "    tokenizer.save_pretrained(new_model_path + output_suffix + \"-final\")\n",
    "    print(f\"Final model saved at {new_model_path + output_suffix + '-final'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3f8dc56-298e-4c56-9c78-a7b4d8ab8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "628662d7-9884-4cd1-91a6-b98ee2ed8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Modify load_model_and_tokenizer function\n",
    "def load_model_and_tokenizer(base_model_path, attn_implementation=\"default\"):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=attn_implementation\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
    "    # model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "    # model.resize_token_embeddings(len(tokenizer))\n",
    "    return model, tokenizer\n",
    "    \n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "# modules = find_all_linear_names(model)\n",
    "# print(modules)\n",
    "# Define LoRA config once since both models use it\n",
    "def create_lora_config(model):\n",
    "    modules = find_all_linear_names(model)\n",
    "    return LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.03,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=modules\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff2b8cee-084a-4510-96b0-ab5c64d57da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Base Model and Tokenizer\n",
    "# print(\"Loading Base Model...\")\n",
    "# base_model, base_tokenizer = load_model_and_tokenizer(\n",
    "#     base_model_path=base_model, \n",
    "#     attn_implementation=attn_implementation\n",
    "# )\n",
    "\n",
    "# # Assert tokenizer and model embedding size match\n",
    "# assert base_model.get_input_embeddings().weight.size(0) == len(base_tokenizer), (\n",
    "#     f\"Model embedding size ({base_model.get_input_embeddings().weight.size(0)}) \"\n",
    "#     f\"does not match tokenizer vocabulary size ({len(base_tokenizer)}).\"\n",
    "# )\n",
    "# # Define LoRA Config\n",
    "# print(\"Creating LoRA Configuration...\")\n",
    "# peft_config = create_lora_config(base_model) \n",
    "\n",
    "# # Apply PEFT to the model\n",
    "# base_model = get_peft_model(base_model, peft_config)\n",
    "# base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "\n",
    "# # Assert tokenizer and model embedding size match\n",
    "# assert base_model.get_input_embeddings().weight.size(0) == len(base_tokenizer), (\n",
    "#     f\"Model embedding size after peft ({base_model.get_input_embeddings().weight.size(0)}) \"\n",
    "#     f\"does not match tokenizer vocabulary size ({len(base_tokenizer)}).\"\n",
    "# )\n",
    "\n",
    "# # Train Base Model on Final Dataset\n",
    "# print(\"Training Base Model on Final Dataset...\")\n",
    "# train_and_save_model(\n",
    "#     model=base_model,\n",
    "#     new_model_path=new_model,\n",
    "#     tokenizer=base_tokenizer,\n",
    "#     train_dataset=final_train_dataset,\n",
    "#     eval_dataset=final_eval_dataset,\n",
    "#     peft_config=peft_config,\n",
    "#     output_suffix=\"base\",\n",
    "#     num_epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "514cfe38-f8e7-42de-915d-fc0cb407b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, tokenizer, input_text):\n",
    "    # Construct the prompt using the same format as in training\n",
    "    prompt = f\"Input:\\n{input_text}\\n\\nLabel:\\n\"\n",
    "\n",
    "    # Tokenize and generate response\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        attention_mask=inputs.get('attention_mask'),\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,  # Ensure decoding stops correctly\n",
    "        forced_bos_token_id=tokenizer.bos_token_id,  # Force beginning of sequence token\n",
    "        temperature=0.8,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "    )\n",
    "\n",
    "    # Decode response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Extract the generated Label section\n",
    "    response_content = response.split(\"Label:\\n\")[-1].strip()\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "277bbfc4-9fa3-4eed-9c7d-c49bf67da5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test prompts\n",
    "# Create an input text\n",
    "input_text = (\n",
    "    \"Gender: Male. \"\n",
    "    \"Age: 32 years old. \"\n",
    "    \"Car Ownership: Yes. \"\n",
    "    \"Property Ownership: Yes. \"\n",
    "    \"Number of Children: 0. \"\n",
    "    \"Annual Income: 427500.0. \"\n",
    "    \"Income Category: Working. \"\n",
    "    \"Education Level: Higher education. \"\n",
    "    \"Marital Status: Civil marriage. \"\n",
    "    \"Housing Type: Rented apartment. \"\n",
    "    \"Employment Duration: 12.44 years. \"\n",
    "    \"Mobile Phone: Yes. \"\n",
    "    \"Work Phone: Yes. \"\n",
    "    \"Email: No. \"\n",
    "    \"Family Size: 2.0.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c81a8a56-6db3-451d-95ce-cb5644f0674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the models\n",
    "# print(\"Testing base model...\")\n",
    "# base_response = test_model(base_model, base_tokenizer, messages)\n",
    "# print(\"Base Model Response:\")\n",
    "# print(base_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc24a096-958e-4a0f-bc87-6d3d14d0434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Instruct Model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab097f2c138410499f22961f268a4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Instruct Model on Final Dataset...\n",
      "Continuing training for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8757f311135542fcb0d45e885b94f625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6759 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ac467ae30744198122c0f4d573295e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1690 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 81.12 MiB is free. Process 130217 has 6.11 GiB memory in use. Process 542626 has 9.70 GiB memory in use. Of the allocated memory 9.22 GiB is allocated by PyTorch, and 196.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train Instruct Model on random Dataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Instruct Model on Final Dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstruct_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstruct_new_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstruct_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_train_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_eval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 29\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[0;34m(model, tokenizer, train_dataset, eval_dataset, peft_config, new_model_path, output_suffix, num_epochs, save_every_n_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         log_labels_and_inputs(batch, predictions, step)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Log evaluation after training\u001b[39;00m\n\u001b[1;32m     32\u001b[0m evaluation_logging(trainer, eval_dataset)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:434\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 434\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/trainer.py:3532\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3531\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3532\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3534\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/peft/peft_model.py:1644\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1643\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1644\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1000\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    988\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    989\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    990\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    997\u001b[0m         position_embeddings,\n\u001b[1;32m    998\u001b[0m     )\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1000\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:745\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    744\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:311\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:467\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# The reason is that in some cases, an error can occur that backprop\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# does not work on a manipulated view. This issue may be solved with\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# newer PyTorch versions but this would need extensive testing to be\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# sure.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:484\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    481\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    483\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:579\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul4Bit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/bitsandbytes/autograd/_functions.py:509\u001b[0m, in \u001b[0;36mMatMul4Bit.forward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m B_shape[:\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# 1. Dequantize\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# 2. MatmulnN\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(A, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdequantize_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(A\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mt(), bias)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;66;03m# 3. Save state\u001b[39;00m\n\u001b[1;32m    512\u001b[0m ctx\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m quant_state\n",
      "File \u001b[0;32m/opt/conda/envs/CC-Chatbot/lib/python3.12/site-packages/bitsandbytes/functional.py:1375\u001b[0m, in \u001b[0;36mdequantize_4bit\u001b[0;34m(A, quant_state, absmax, out, blocksize, quant_type)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         absmax \u001b[38;5;241m=\u001b[39m absmax\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m n \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m   1379\u001b[0m device \u001b[38;5;241m=\u001b[39m pre_call(A\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 81.12 MiB is free. Process 130217 has 6.11 GiB memory in use. Process 542626 has 9.70 GiB memory in use. Of the allocated memory 9.22 GiB is allocated by PyTorch, and 196.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Load Instruct Model\n",
    "print(\"Loading Instruct Model...\")\n",
    "instruct_model, instruct_tokenizer = load_model_and_tokenizer(\n",
    "    base_model_path=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    attn_implementation=attn_implementation\n",
    "\n",
    ")\n",
    "instruct_tokenizer.pad_token = instruct_tokenizer.eos_token\n",
    "\n",
    "# Assert tokenizer and model embedding size match\n",
    "assert instruct_model.get_input_embeddings().weight.size(0) == len(instruct_tokenizer), (\n",
    "    f\"Model embedding size after peft ({instruct_model.get_input_embeddings().weight.size(0)}) \"\n",
    "    f\"does not match tokenizer vocabulary size ({len(instruct_tokenizer)}).\"\n",
    ")\n",
    "\n",
    "peft_config = create_lora_config(instruct_model)\n",
    "\n",
    "# Apply PEFT to the model\n",
    "instruct_model = get_peft_model(instruct_model, peft_config)\n",
    "\n",
    "# Train Instruct Model on random Dataset\n",
    "print(\"Training Instruct Model on Final Dataset...\")\n",
    "train_and_save_model(\n",
    "    model=instruct_model,\n",
    "    new_model_path=instruct_new_model,\n",
    "    tokenizer=instruct_tokenizer,\n",
    "    train_dataset=final_train_dataset,\n",
    "    eval_dataset=final_eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    output_suffix=\"instruct\",\n",
    "    num_epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e82bd-7442-4d87-bb5b-27ed716fbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing instruct model...\")\n",
    "instruct_response = test_model(base_model, base_tokenizer, messages)\n",
    "print(\"Instruct Model Response:\")\n",
    "print(instruct_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03e05e-8238-415e-9ae7-3891c0eabd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close WandB session\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfd4b8-02e8-4e74-8613-59934f551218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CC-Chatbot)",
   "language": "python",
   "name": "cc-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
